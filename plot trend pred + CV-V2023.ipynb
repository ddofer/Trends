{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63a5d2b",
   "metadata": {},
   "source": [
    "##### Publication trends forecasting outputs\n",
    "\n",
    "* Train+val+test Data covers ~1960-2019.\n",
    "    * Model/features optimized over 1980-2010\n",
    "\n",
    "* Prediction 5 years (inclusive) in advance\n",
    "\n",
    "* Temporal split over data\n",
    "\n",
    "* `y_raw` = Actual amount of publications (normalized out of total pubs that year in pubmed)\n",
    "* `preds` = model predictions\n",
    "\n",
    "\n",
    "* SparkBeyond Validation set ~ 2010-2013 , Test set 2014-2019\n",
    "    * SB Train+val+test Data covers 1980-2019.\n",
    "    * Raw/context data covers more (and I output that here)\n",
    "* Prediction 5 years (inclusive) in advance\n",
    "\n",
    "\n",
    " * I try redoing time series CV/split here from scratch , to better show predicitons. \n",
    "     * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17021a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict,TimeSeriesSplit\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor \n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV, ElasticNet,ElasticNetCV, Lasso\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "import sklearn.metrics as metrics\n",
    "from  sklearn.metrics import classification_report\n",
    "import re\n",
    "pd.set_option('mode.use_inf_as_na', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d7fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_GROUP_SIZES = True\n",
    "\n",
    "DIFF_TARGET = True#False#True # set target to diff vs 5 years ago. i.e tougher baseline\n",
    "DIFF_TARGET_PCT = False#True#False#True\n",
    "NUM_CV_FOLDS =  30#5#30 #\n",
    "\n",
    "DO_RFE_FS = False#False#True\n",
    "\n",
    "GET_DL_EMBEDS = True#False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30720785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_preds(df,val:str=\"subthalamus\",logScale=False):\n",
    "#     df.loc[df[\"variable\"].str.contains(val,case=False)][[\"y_raw\",\"preds\"]].plot(title=val)# \"y_raw_predicted\"\n",
    "    if logScale:\n",
    "        df.loc[df[\"variable\"].str.lower()==val.lower()][[\"y_raw\",\"preds\"]].apply(np.log1p).plot(title=val)\n",
    "    else:\n",
    "        df.loc[df[\"variable\"].str.lower()==val.lower()][[\"y_raw\",\"preds\"]].plot(title=val)\n",
    "    \n",
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('r2:', round(r2,3))\n",
    "    print('MAE (Mean absolute error):', round(mean_absolute_error,3))\n",
    "    print('Median absolute error:', round(median_absolute_error,3))\n",
    "#     print('MSE: ', round(mse,3))\n",
    "    print('RMSE:', round(np.sqrt(mse),3))\n",
    "    print('explained_variance: ', round(explained_variance,3))    \n",
    "    try:\n",
    "        mape = metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "        print('mape:', round(mape,3))\n",
    "    except:()\n",
    "    try: \n",
    "        mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "        print('mean_squared_log_error:', round(mean_squared_log_error,3))\n",
    "    except:()\n",
    "\n",
    "        \n",
    "def evaluate(model = CatBoostRegressor(cat_features= [\"variable\"],verbose=False,has_time=True),X = None):\n",
    "    \"\"\"\n",
    "    Assigns results of preictions to df_feat (global var version)\n",
    "    https://stats.stackexchange.com/questions/495151/cross-validation-for-time-series-what-am-i-doing-wrong\n",
    "    https://stackoverflow.com/questions/51597507/sklearn-timeseriessplit-error-keyerror-0-1-2-not-in-index\n",
    "    \"\"\"\n",
    "    # train model on training dataset\n",
    "    i = 0\n",
    "    tscv = TimeSeriesSplit(NUM_CV_FOLDS) #10) # ORIG - 10\n",
    "#     df_feat[\"preds\"] = np.NaN # un commented - DAN - new\n",
    "    for train_index, test_index in tscv.split(X): #df_feat):\n",
    "        i +=1\n",
    "#         print(i)\n",
    "        if i%3==0: print(i)\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         X_train, X_test = X.index[train_index], X.index[test_index]#X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "#         model = CatBoostRegressor(iterations=500,\n",
    "#                                   cat_features= [\"variable\"],#[0], #[\"variable\"],\n",
    "#                           verbose=False,has_time=True)\n",
    "#         print(\"fit\")\n",
    "#         model.fit(X_train, y_train)\n",
    "        model.fit(X_train, y_train,\n",
    "#                   early_stopping_rounds=10,\n",
    "#                   eval_set=(X_test, y_test),\n",
    "                  #plot=(i%3==0),\n",
    "#                  baseline=X_train[\"lag5\"].values)#pd.concat([X_train[\"lag5\"],X_test[\"lag5\"]]).values)\n",
    "                  )\n",
    "#         print(\"doing pred\")\n",
    "        y_predict = model.predict(X_test)\n",
    "        assert np.isnan(y_predict).max() == False\n",
    "#         print(\"assigning pred\")\n",
    "#         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "        df_feat.iloc[test_index,-1] =y_predict  ##\n",
    "    print(\"\\n Done\")\n",
    "\n",
    "def truncate(f2, n=1):\n",
    "    '''Truncates/pads a float f to n decimal places without rounding'''\n",
    "#     if f.isnumeric():\n",
    "    try: \n",
    "        f = float(f2)\n",
    "#         s = '{}'.format(f)\n",
    "#         if 'e' in s or 'E' in s:\n",
    "#             return '{0:.{1}f}'.format(f, n)\n",
    "#         i, p, d = s.partition('.')\n",
    "#         return '.'.join([i, (d+'0'*n)[:n]])\n",
    "        return(str(round(float(f),2)))\n",
    "#     else:\n",
    "    except:\n",
    "        return f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d4a10",
   "metadata": {},
   "source": [
    "#### plot (lagged?) correlation of inputs and target in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c6dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4798, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1135/370888971.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_targets = pd.read_csv(\"trends_v6.csv.gz\",parse_dates=[\"Year\",\"first\",\"start\"],infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>variable</th>\n",
       "      <th>y_raw</th>\n",
       "      <th>reviews</th>\n",
       "      <th>research_review_diff</th>\n",
       "      <th>research_review_ratio</th>\n",
       "      <th>pct_diff</th>\n",
       "      <th>patent_count</th>\n",
       "      <th>patent_frac</th>\n",
       "      <th>patent_yearly_total</th>\n",
       "      <th>...</th>\n",
       "      <th>pat_div_research</th>\n",
       "      <th>year_num</th>\n",
       "      <th>y_diff</th>\n",
       "      <th>y_pct_diff</th>\n",
       "      <th>diff_lag5</th>\n",
       "      <th>diff_lag6</th>\n",
       "      <th>pct_diff_lag5</th>\n",
       "      <th>pct_diff_lag6</th>\n",
       "      <th>target_5</th>\n",
       "      <th>lag5_pct_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>103.5087</td>\n",
       "      <td>1.4179</td>\n",
       "      <td>103.5087</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4.5645</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>1979</td>\n",
       "      <td>-2.8860</td>\n",
       "      <td>-0.027125</td>\n",
       "      <td>63.1021</td>\n",
       "      <td>69.3282</td>\n",
       "      <td>0.182154</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>150.1954</td>\n",
       "      <td>60.963088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Brodmann area</td>\n",
       "      <td>2.1269</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-4.2538</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1979</td>\n",
       "      <td>1.0263</td>\n",
       "      <td>0.932491</td>\n",
       "      <td>1.7016</td>\n",
       "      <td>2.1269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1422</td>\n",
       "      <td>80.003761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Cingulate cortex</td>\n",
       "      <td>13.8248</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.8248</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1979</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>-0.008364</td>\n",
       "      <td>-2.3378</td>\n",
       "      <td>-6.9431</td>\n",
       "      <td>-0.221751</td>\n",
       "      <td>0.631850</td>\n",
       "      <td>25.1373</td>\n",
       "      <td>-16.910190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>DNA array</td>\n",
       "      <td>4.2538</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>4.2538</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1979</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.159453</td>\n",
       "      <td>3.4031</td>\n",
       "      <td>3.3885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1971</td>\n",
       "      <td>80.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Dorsolateral prefrontal cortex</td>\n",
       "      <td>1.0634</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-40.0564</td>\n",
       "      <td>-37.6667</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1979</td>\n",
       "      <td>-1.5047</td>\n",
       "      <td>-0.585920</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8279</td>\n",
       "      <td>60.005642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>EEG</td>\n",
       "      <td>719.9524</td>\n",
       "      <td>20.5599</td>\n",
       "      <td>699.0379</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>1979</td>\n",
       "      <td>16.6468</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>-226.4131</td>\n",
       "      <td>-321.0382</td>\n",
       "      <td>-0.090899</td>\n",
       "      <td>-0.016952</td>\n",
       "      <td>683.1065</td>\n",
       "      <td>-31.448343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Epidemiology</td>\n",
       "      <td>3853.2162</td>\n",
       "      <td>153.1361</td>\n",
       "      <td>3853.2162</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1979</td>\n",
       "      <td>178.1969</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>-510.6986</td>\n",
       "      <td>-559.9610</td>\n",
       "      <td>-0.011163</td>\n",
       "      <td>0.079809</td>\n",
       "      <td>4098.6388</td>\n",
       "      <td>-13.253827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year                        variable      y_raw   reviews  \\\n",
       "0 1979-01-01                           BLAST   103.5087    1.4179   \n",
       "1 1979-01-01                   Brodmann area     2.1269    0.0000   \n",
       "2 1979-01-01                Cingulate cortex    13.8248    0.0000   \n",
       "3 1979-01-01                       DNA array     4.2538    0.3545   \n",
       "4 1979-01-01  Dorsolateral prefrontal cortex     1.0634    0.0000   \n",
       "5 1979-01-01                             EEG   719.9524   20.5599   \n",
       "6 1979-01-01                    Epidemiology  3853.2162  153.1361   \n",
       "\n",
       "   research_review_diff  research_review_ratio  pct_diff  patent_count  \\\n",
       "0              103.5087                 1.0000   -0.0271          87.0   \n",
       "1               -4.2538                -2.0000    0.9324           0.0   \n",
       "2               13.8248                 1.0000   -0.0084           0.0   \n",
       "3                4.2538                 1.0000    0.1595           0.0   \n",
       "4              -40.0564               -37.6667   -0.5859           0.0   \n",
       "5              699.0379                 0.9710    0.0237           1.0   \n",
       "6             3853.2162                 1.0000    0.0485           0.0   \n",
       "\n",
       "   patent_frac  patent_yearly_total  ...  pat_div_research  year_num  \\\n",
       "0       4.5645               1906.0  ...            0.8405      1979   \n",
       "1       0.0000               1906.0  ...            0.0000      1979   \n",
       "2       0.0000               1906.0  ...            0.0000      1979   \n",
       "3       0.0000               1906.0  ...            0.0000      1979   \n",
       "4       0.0000               1906.0  ...            0.0000      1979   \n",
       "5       0.0525               1906.0  ...            0.0014      1979   \n",
       "6       0.0000               1906.0  ...            0.0000      1979   \n",
       "\n",
       "     y_diff y_pct_diff  diff_lag5  diff_lag6  pct_diff_lag5  pct_diff_lag6  \\\n",
       "0   -2.8860  -0.027125    63.1021    69.3282       0.182154       0.052524   \n",
       "1    1.0263   0.932491     1.7016     2.1269            NaN            NaN   \n",
       "2   -0.1166  -0.008364    -2.3378    -6.9431      -0.221751       0.631850   \n",
       "3    0.5850   0.159453     3.4031     3.3885            NaN            NaN   \n",
       "4   -1.5047  -0.585920     0.6381     0.6307            NaN            NaN   \n",
       "5   16.6468   0.023669  -226.4131  -321.0382      -0.090899      -0.016952   \n",
       "6  178.1969   0.048489  -510.6986  -559.9610      -0.011163       0.079809   \n",
       "\n",
       "    target_5  lag5_pct_new  \n",
       "0   150.1954     60.963088  \n",
       "1     3.1422     80.003761  \n",
       "2    25.1373    -16.910190  \n",
       "3    13.1971     80.001411  \n",
       "4     2.8279     60.005642  \n",
       "5   683.1065    -31.448343  \n",
       "6  4098.6388    -13.253827  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets = pd.read_csv(\"trends_v6.csv.gz\",parse_dates=[\"Year\",\"first\",\"start\"],infer_datetime_format=True)\n",
    "\n",
    "#### NEW! Sort by date!\n",
    "df_targets = df_targets.sort_values([\"Year\",\"variable\"])\n",
    "df_targets[\"target_5\"] = df_targets.groupby(\"variable\")[\"y_raw\"].shift(-5) ## target in 5 years\n",
    "\n",
    "# df_targets[[\"Year\",\"variable\",\"y_raw\",\"target_5\"]]\n",
    "df_targets = df_targets.loc[(df_targets[\"Year\"]> df_targets[\"start\"]) & (df_targets[\"year_num\"]>= 1979) ]\n",
    "df_targets.drop(columns=[\n",
    "#                          \"pct_diff_lag6\",\n",
    "    \"y_pct_bins\",\n",
    "#                          \"y_pct_diff\",\"year_num\",\n",
    "                         \"lag1\",\"lag2\",\"lag3\",\"lag4\",\n",
    "##ORIG: was commented out! be careful! #                          \"diff_lag6\",\"lag6\",\n",
    "#                          \"pct_diff_lag5\",\n",
    "#                          \"first\",\"start\"\n",
    "            ],errors=\"ignore\",inplace=True)\n",
    "print(df_targets.shape)\n",
    "df_targets[\"lag5_pct_new\"] = 100*df_targets[\"diff_lag5\"].div(df_targets[\"y_raw\"])# pct diff vs 5 years ago\n",
    "\n",
    "df_targets = df_targets.reset_index(drop=True)\n",
    "\n",
    "df_targets.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea3713d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_5</th>\n",
       "      <th>y_raw</th>\n",
       "      <th>reviews</th>\n",
       "      <th>first</th>\n",
       "      <th>start</th>\n",
       "      <th>start_sub_first</th>\n",
       "      <th>year_sub_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target_5</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.902</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_raw</th>\n",
       "      <td>0.987</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.905</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.128</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_sub_first</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>0.098</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_sub_start</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target_5  y_raw  reviews  first  start  start_sub_first  \\\n",
       "target_5            1.000  0.987    0.902 -0.027 -0.223           -0.030   \n",
       "y_raw               0.987  1.000    0.905 -0.021 -0.229           -0.031   \n",
       "reviews             0.902  0.905    1.000 -0.021 -0.217           -0.028   \n",
       "first              -0.027 -0.021   -0.021  1.000  0.128           -0.975   \n",
       "start              -0.223 -0.229   -0.217  0.128  1.000            0.098   \n",
       "start_sub_first    -0.030 -0.031   -0.028 -0.975  0.098            1.000   \n",
       "year_sub_start      0.236  0.250    0.281 -0.056 -0.724           -0.107   \n",
       "\n",
       "                 year_sub_start  \n",
       "target_5                  0.236  \n",
       "y_raw                     0.250  \n",
       "reviews                   0.281  \n",
       "first                    -0.056  \n",
       "start                    -0.724  \n",
       "start_sub_first          -0.107  \n",
       "year_sub_start            1.000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets[\"first\"] = df_targets[\"first\"].str.split(\"-\",expand=True)[0].astype(int)\n",
    "df_targets[\"start\"] = pd.to_datetime(df_targets[\"start\"]).dt.year.astype(int)\n",
    "df_targets[\"start_sub_first\"] = df_targets[\"start\"].sub(df_targets[\"first\"])\n",
    "df_targets[\"year_sub_start\"] = df_targets[\"year_num\"].sub(df_targets[\"start\"])\n",
    "df_targets[[\"target_5\",\"y_raw\",\"reviews\",\"first\",\"start\",\"start_sub_first\",\"year_sub_start\"]].corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2303841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>variable</th>\n",
       "      <th>y_raw</th>\n",
       "      <th>reviews</th>\n",
       "      <th>research_review_diff</th>\n",
       "      <th>research_review_ratio</th>\n",
       "      <th>pct_diff</th>\n",
       "      <th>patent_count</th>\n",
       "      <th>patent_frac</th>\n",
       "      <th>patent_yearly_total</th>\n",
       "      <th>...</th>\n",
       "      <th>y_diff</th>\n",
       "      <th>y_pct_diff</th>\n",
       "      <th>diff_lag5</th>\n",
       "      <th>diff_lag6</th>\n",
       "      <th>pct_diff_lag5</th>\n",
       "      <th>pct_diff_lag6</th>\n",
       "      <th>target_5</th>\n",
       "      <th>lag5_pct_new</th>\n",
       "      <th>start_sub_first</th>\n",
       "      <th>year_sub_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>103.5087</td>\n",
       "      <td>1.4179</td>\n",
       "      <td>103.5087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4.5645</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.8860</td>\n",
       "      <td>-0.027125</td>\n",
       "      <td>63.1021</td>\n",
       "      <td>69.3282</td>\n",
       "      <td>0.182154</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>150.1954</td>\n",
       "      <td>60.963088</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>103.3293</td>\n",
       "      <td>2.8505</td>\n",
       "      <td>103.3293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.7221</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1794</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>-3.8170</td>\n",
       "      <td>62.9227</td>\n",
       "      <td>1.651703</td>\n",
       "      <td>0.182154</td>\n",
       "      <td>168.4701</td>\n",
       "      <td>-3.694015</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>144.5499</td>\n",
       "      <td>1.7628</td>\n",
       "      <td>144.5499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3989</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4.1517</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.2206</td>\n",
       "      <td>0.398925</td>\n",
       "      <td>31.5976</td>\n",
       "      <td>37.4036</td>\n",
       "      <td>0.054188</td>\n",
       "      <td>1.651703</td>\n",
       "      <td>168.6982</td>\n",
       "      <td>21.859303</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>129.1531</td>\n",
       "      <td>2.0286</td>\n",
       "      <td>129.1531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1065</td>\n",
       "      <td>134.0</td>\n",
       "      <td>5.7338</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.3968</td>\n",
       "      <td>-0.106515</td>\n",
       "      <td>35.3287</td>\n",
       "      <td>16.2008</td>\n",
       "      <td>-0.169345</td>\n",
       "      <td>0.054188</td>\n",
       "      <td>186.4166</td>\n",
       "      <td>27.354125</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1983-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>147.9653</td>\n",
       "      <td>2.5845</td>\n",
       "      <td>147.9653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>126.0</td>\n",
       "      <td>5.5975</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.8122</td>\n",
       "      <td>0.145658</td>\n",
       "      <td>41.5706</td>\n",
       "      <td>54.1409</td>\n",
       "      <td>0.133977</td>\n",
       "      <td>-0.169345</td>\n",
       "      <td>184.7340</td>\n",
       "      <td>28.094830</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>150.1954</td>\n",
       "      <td>2.5137</td>\n",
       "      <td>150.1954</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4.2536</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2301</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>46.6867</td>\n",
       "      <td>43.8007</td>\n",
       "      <td>-0.027125</td>\n",
       "      <td>0.133977</td>\n",
       "      <td>198.6063</td>\n",
       "      <td>31.083975</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>168.4701</td>\n",
       "      <td>3.8763</td>\n",
       "      <td>168.4701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.9367</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2747</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>65.1408</td>\n",
       "      <td>64.9614</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>-0.027125</td>\n",
       "      <td>186.9095</td>\n",
       "      <td>38.666090</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year variable     y_raw  reviews  research_review_diff  \\\n",
       "0   1979-01-01    BLAST  103.5087   1.4179              103.5087   \n",
       "98  1980-01-01    BLAST  103.3293   2.8505              103.3293   \n",
       "199 1981-01-01    BLAST  144.5499   1.7628              144.5499   \n",
       "302 1982-01-01    BLAST  129.1531   2.0286              129.1531   \n",
       "406 1983-01-01    BLAST  147.9653   2.5845              147.9653   \n",
       "511 1984-01-01    BLAST  150.1954   2.5137              150.1954   \n",
       "618 1985-01-01    BLAST  168.4701   3.8763              168.4701   \n",
       "\n",
       "     research_review_ratio  pct_diff  patent_count  patent_frac  \\\n",
       "0                      1.0   -0.0271          87.0       4.5645   \n",
       "98                     1.0   -0.0017         113.0       4.7221   \n",
       "199                    1.0    0.3989         104.0       4.1517   \n",
       "302                    1.0   -0.1065         134.0       5.7338   \n",
       "406                    1.0    0.1457         126.0       5.5975   \n",
       "511                    1.0    0.0151         104.0       4.2536   \n",
       "618                    1.0    0.1217          77.0       2.9367   \n",
       "\n",
       "     patent_yearly_total  ...   y_diff  y_pct_diff  diff_lag5  diff_lag6  \\\n",
       "0                 1906.0  ...  -2.8860   -0.027125    63.1021    69.3282   \n",
       "98                2393.0  ...  -0.1794   -0.001733    -3.8170    62.9227   \n",
       "199               2505.0  ...  41.2206    0.398925    31.5976    37.4036   \n",
       "302               2337.0  ... -15.3968   -0.106515    35.3287    16.2008   \n",
       "406               2251.0  ...  18.8122    0.145658    41.5706    54.1409   \n",
       "511               2445.0  ...   2.2301    0.015072    46.6867    43.8007   \n",
       "618               2622.0  ...  18.2747    0.121673    65.1408    64.9614   \n",
       "\n",
       "     pct_diff_lag5  pct_diff_lag6  target_5  lag5_pct_new  start_sub_first  \\\n",
       "0         0.182154       0.052524  150.1954     60.963088                5   \n",
       "98        1.651703       0.182154  168.4701     -3.694015                5   \n",
       "199       0.054188       1.651703  168.6982     21.859303                5   \n",
       "302      -0.169345       0.054188  186.4166     27.354125                5   \n",
       "406       0.133977      -0.169345  184.7340     28.094830                5   \n",
       "511      -0.027125       0.133977  198.6063     31.083975                5   \n",
       "618      -0.001733      -0.027125  186.9095     38.666090                5   \n",
       "\n",
       "     year_sub_start  \n",
       "0                29  \n",
       "98               30  \n",
       "199              31  \n",
       "302              32  \n",
       "406              33  \n",
       "511              34  \n",
       "618              35  \n",
       "\n",
       "[7 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>variable</th>\n",
       "      <th>y_raw</th>\n",
       "      <th>reviews</th>\n",
       "      <th>research_review_diff</th>\n",
       "      <th>research_review_ratio</th>\n",
       "      <th>pct_diff</th>\n",
       "      <th>patent_count</th>\n",
       "      <th>patent_frac</th>\n",
       "      <th>patent_yearly_total</th>\n",
       "      <th>...</th>\n",
       "      <th>y_diff</th>\n",
       "      <th>y_pct_diff</th>\n",
       "      <th>diff_lag5</th>\n",
       "      <th>diff_lag6</th>\n",
       "      <th>pct_diff_lag5</th>\n",
       "      <th>pct_diff_lag6</th>\n",
       "      <th>target_5</th>\n",
       "      <th>lag5_pct_new</th>\n",
       "      <th>start_sub_first</th>\n",
       "      <th>year_sub_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>235.4479</td>\n",
       "      <td>22.0681</td>\n",
       "      <td>88.0233</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>-0.0153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19662.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.6511</td>\n",
       "      <td>-0.015270</td>\n",
       "      <td>38.4216</td>\n",
       "      <td>46.4562</td>\n",
       "      <td>0.042513</td>\n",
       "      <td>0.074991</td>\n",
       "      <td>287.7659</td>\n",
       "      <td>16.318515</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>238.4186</td>\n",
       "      <td>20.7563</td>\n",
       "      <td>79.4464</td>\n",
       "      <td>0.3332</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19640.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9707</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>35.5586</td>\n",
       "      <td>41.3923</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>0.042513</td>\n",
       "      <td>273.3293</td>\n",
       "      <td>14.914357</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>264.3801</td>\n",
       "      <td>24.0558</td>\n",
       "      <td>96.9238</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19578.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.9615</td>\n",
       "      <td>0.108890</td>\n",
       "      <td>36.3338</td>\n",
       "      <td>61.5201</td>\n",
       "      <td>0.124156</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.743016</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>260.2324</td>\n",
       "      <td>23.8668</td>\n",
       "      <td>79.5815</td>\n",
       "      <td>0.3058</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>21165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.1477</td>\n",
       "      <td>-0.015688</td>\n",
       "      <td>35.9295</td>\n",
       "      <td>32.1861</td>\n",
       "      <td>-0.016415</td>\n",
       "      <td>0.124156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.806697</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>273.0933</td>\n",
       "      <td>21.4016</td>\n",
       "      <td>112.5070</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>20638.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8609</td>\n",
       "      <td>0.049421</td>\n",
       "      <td>33.9943</td>\n",
       "      <td>48.7904</td>\n",
       "      <td>0.065965</td>\n",
       "      <td>-0.016415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.447870</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>287.7659</td>\n",
       "      <td>23.2825</td>\n",
       "      <td>138.4172</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23994.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6726</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>52.3180</td>\n",
       "      <td>48.6669</td>\n",
       "      <td>-0.015270</td>\n",
       "      <td>0.065965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.180750</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>273.3293</td>\n",
       "      <td>22.3980</td>\n",
       "      <td>125.3426</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>25883.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.4366</td>\n",
       "      <td>-0.050168</td>\n",
       "      <td>34.9107</td>\n",
       "      <td>37.8814</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>-0.015270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.772396</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year    variable     y_raw  reviews  research_review_diff  \\\n",
       "4057 2014-01-01  zebra fish  235.4479  22.0681               88.0233   \n",
       "4180 2015-01-01  zebra fish  238.4186  20.7563               79.4464   \n",
       "4303 2016-01-01  zebra fish  264.3801  24.0558               96.9238   \n",
       "4426 2017-01-01  zebra fish  260.2324  23.8668               79.5815   \n",
       "4549 2018-01-01  zebra fish  273.0933  21.4016              112.5070   \n",
       "4673 2019-01-01  zebra fish  287.7659  23.2825              138.4172   \n",
       "4797 2020-01-01  zebra fish  273.3293  22.3980              125.3426   \n",
       "\n",
       "      research_review_ratio  pct_diff  patent_count  patent_frac  \\\n",
       "4057                 0.3739   -0.0153           0.0       0.0000   \n",
       "4180                 0.3332    0.0126           0.0       0.0000   \n",
       "4303                 0.3666    0.1089           0.0       0.0000   \n",
       "4426                 0.3058   -0.0157           1.0       0.0047   \n",
       "4549                 0.4120    0.0494           1.0       0.0048   \n",
       "4673                 0.4810    0.0537           0.0       0.0000   \n",
       "4797                 0.4586   -0.0502           1.0       0.0039   \n",
       "\n",
       "      patent_yearly_total  ...   y_diff  y_pct_diff  diff_lag5  diff_lag6  \\\n",
       "4057              19662.0  ...  -3.6511   -0.015270    38.4216    46.4562   \n",
       "4180              19640.0  ...   2.9707    0.012617    35.5586    41.3923   \n",
       "4303              19578.0  ...  25.9615    0.108890    36.3338    61.5201   \n",
       "4426              21165.0  ...  -4.1477   -0.015688    35.9295    32.1861   \n",
       "4549              20638.0  ...  12.8609    0.049421    33.9943    48.7904   \n",
       "4673              23994.0  ...  14.6726    0.053727    52.3180    48.6669   \n",
       "4797              25883.0  ... -14.4366   -0.050168    34.9107    37.8814   \n",
       "\n",
       "      pct_diff_lag5  pct_diff_lag6  target_5  lag5_pct_new  start_sub_first  \\\n",
       "4057       0.042513       0.074991  287.7659     16.318515                5   \n",
       "4180       0.029609       0.042513  273.3293     14.914357                5   \n",
       "4303       0.124156       0.029609       NaN     13.743016                5   \n",
       "4426      -0.016415       0.124156       NaN     13.806697                5   \n",
       "4549       0.065965      -0.016415       NaN     12.447870                5   \n",
       "4673      -0.015270       0.065965       NaN     18.180750                5   \n",
       "4797       0.012617      -0.015270       NaN     12.772396                5   \n",
       "\n",
       "      year_sub_start  \n",
       "4057              61  \n",
       "4180              62  \n",
       "4303              63  \n",
       "4426              64  \n",
       "4549              65  \n",
       "4673              66  \n",
       "4797              67  \n",
       "\n",
       "[7 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_targets.sort_values([\"variable\",\"Year\"]).head(7))\n",
    "display(df_targets.sort_values([\"variable\",\"Year\"]).tail(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47adf239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4798\n",
      "4790\n",
      "DIFF_TARGET\n",
      "differencing of target applied\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_5</th>\n",
       "      <th>y_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4175.000</td>\n",
       "      <td>4175.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>117.053</td>\n",
       "      <td>623.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>385.901</td>\n",
       "      <td>1299.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1351.747</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.584</td>\n",
       "      <td>29.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.162</td>\n",
       "      <td>170.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>116.739</td>\n",
       "      <td>565.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3919.521</td>\n",
       "      <td>11909.162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_5      y_raw\n",
       "count  4175.000   4175.000\n",
       "mean    117.053    623.469\n",
       "std     385.901   1299.120\n",
       "min   -1351.747      0.000\n",
       "25%      -9.584     29.440\n",
       "50%      15.162    170.474\n",
       "75%     116.739    565.663\n",
       "max    3919.521  11909.162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if FILTER_GROUP_SIZES:\n",
    "    print(df_targets.shape[0])\n",
    "    element_group_sizes = df_targets['variable'].groupby(df_targets['variable']).transform('count')\n",
    "    df_targets = df_targets[element_group_sizes>6] # was 5, changed for CV results\n",
    "    df_targets.reset_index(inplace=True,drop=True) # otherwise, error ?? \n",
    "    print(df_targets.shape[0])\n",
    "\n",
    "if DIFF_TARGET_PCT:\n",
    "    print(\"DIFF_TARGET_PCT\")\n",
    "    df_targets[\"target_5\"] = 100*df_targets[\"target_5\"].sub(df_targets[\"lag5\"]).div(df_targets[\"y_raw\"]).round(4) # alt, pct change target\n",
    "#     df_targets[\"y_raw\"] = 100*df_targets[\"y_raw\"].div(df_targets[\"lag5\"]).round(4) # alt, pct change target\n",
    "elif DIFF_TARGET:\n",
    "    print(\"DIFF_TARGET\")\n",
    "    df_targets[\"target_5\"] = df_targets[\"target_5\"].sub(df_targets[\"lag5\"])\n",
    "#     df_targets[\"y_raw\"] = df_targets[\"y_raw\"].sub(df_targets[\"lag5\"]) # not needed? \n",
    "#     df_targets[\"y_raw\"] = df_targets[\"y_raw\"].div(df_targets[\"lag5\"]) # alt, pct change target\n",
    "if DIFF_TARGET_PCT or DIFF_TARGET:\n",
    "    print(\"differencing of target applied\")\n",
    "#     df_targets.dropna(subset=[\"y_raw\"],inplace=True)\n",
    "    df_targets_orig_full = df_targets.copy() # new, keep copy of full data for getting future preds\n",
    "    df_targets.dropna(subset=[\"target_5\"],inplace=True) ## originally we dropped - keep these for predictions! \n",
    "    df_targets.reset_index(inplace=True,drop=True)\n",
    "    display(df_targets[[\"target_5\",\"y_raw\"]].describe().round(3))\n",
    "else:\n",
    "    df_targets_orig_full = df_targets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89436916",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DIFF_TARGET_PCT:\n",
    "    print(\"percent differenced target has some outliers (especially around start of a topic) and some extreme values (11,644)\")\n",
    "    ### extreme growth topics - subthalamus, rnai, MRI, fMRI, carbon nanotubes, perceptron - makes sense\n",
    "    display(df_targets[df_targets[\"target_5\"]>3000].sort_values([\"target_5\"],ascending=False).filter([\"Year\",\"variable\",\"y_raw\",\"target_5\"],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3e5f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.451"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets[\"target_5\"].corr(df_targets['y_raw']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8019c",
   "metadata": {},
   "source": [
    "## Fig S2- Increasing popularity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ed7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Increasing popularity over time'}, xlabel='Year', ylabel='Average popularity of all topics'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHFCAYAAADv8c1wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAByfklEQVR4nO3dd1hT1/8H8HfCCEMIsoeIuAe4cGLdW3HvbbXTvb51/GrVDrW2VtvapbVatRVbV61arXuiImoFtYobFGQnzADJ+f1BSU1BTTAQxvv1PHkg95577+ceLuTDOeeeKxFCCBARERHRc0lNHQARERFRWcCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkicq1jRs3QiKR4OLFi6YOpUTcv38fEokEGzduNHUopdbx48chkUhw/Phxo+43/1q7f/++dtnPP/+M1atXG/U4Zcn+/fuxePHiQtdVq1YN48ePL9F4iF4WkyaicsTDwwMhISHo3bu3qUOpcHr37o2QkBB4eHholzFp2o8lS5YUum7Xrl1YuHBhCUdE9HLMTR0AUXkjhEBWVhasra1L/NgymQytWrUq8eNWZJmZmbCysoKLiwtcXFxMHU6Jy8jIgI2NjcHbNWnSpBiiISpebGmiCmf8+PGoVKkSbt++jV69eqFSpUrw9vbG7NmzoVKpdMqqVCq8//77qFevHqysrODk5ISOHTvi7Nmz2jISiQRTpkzBt99+i3r16kEmk+HHH38EAERGRmLkyJFwdXWFTCZDvXr18NVXX+kcIysrC7Nnz0bjxo0hl8vh6OiI1q1b47fffisQ+6+//oqWLVtCLpfDxsYG1atXx4QJE7TrC+ueW7x4MSQSCa5du4YRI0ZALpfDzc0NEyZMgEKh0Nl/SkoKJk6cCEdHR1SqVAm9e/fG3bt3IZFIntnNki+/22vLli2YNWsW3N3dYW1tjfbt2+Py5csFyu/ZswetW7eGjY0N7Ozs0LVrV4SEhOiUyY/98uXLGDhwIOzt7SGXyzF69GjEx8frlH1WjPp0A128eBHDhw9HtWrVYG1tjWrVqmHEiBF48OCBTrn8Lrg///wTEyZMgIuLC2xsbKBSqQp0z3Xo0AH79u3DgwcPIJFItC8hBGrVqoXu3bsXiCMtLQ1yuRyTJ09+brxZWVmYP38+fH19YWlpCS8vL0yePBkpKSnaMv3794ePjw80Gk2B7Vu2bImmTZtq3wsh8PXXX6Nx48awtrZG5cqVMXjwYNy9e1dnuw4dOsDPzw8nT55EYGAgbGxsdK6/p40fP157rT99/vn189+fS/718/PPP2Pu3Lnw8PBApUqV0KdPHzx58gSpqal444034OzsDGdnZ7z66qtIS0vTOaa+50FUVEyaqELKyclB37590blzZ/z222+YMGECVq1ahY8//lhbJjc3Fz179sQHH3yAoKAg7Nq1Cxs3bkRgYCAePnyos7/du3fjm2++wXvvvYeDBw+ibdu2uH79Opo3b46IiAisXLkSe/fuRe/evTFt2jSdLguVSoWkpCTMmTMHu3fvxtatW/HKK69g4MCB2LRpk7ZcSEgIhg0bhurVqyM4OBj79u3De++9h9zcXL3OedCgQahduzZ27NiBefPm4eeff8bMmTO16zUaDfr06aP90Nq1axdatmyJHj16GFS3CxYswN27d/H999/j+++/x+PHj9GhQwedD66ff/4Z/fr1g729PbZu3Yr169cjOTkZHTp0wOnTpwvsc8CAAahZsya2b9+OxYsXY/fu3ejevTtycnIMiu1Z7t+/jzp16mD16tU4ePAgPv74Y8TExKB58+ZISEgoUH7ChAmwsLDA5s2bsX37dlhYWBQo8/XXX6NNmzZwd3dHSEiI9iWRSDB16lQcOnQIkZGROtts2rQJSqXyuUmTEAL9+/fHp59+ijFjxmDfvn2YNWsWfvzxR3Tq1Emb+E+YMAEPHz7E0aNHdbb/+++/ceHCBbz66qvaZW+++SZmzJiBLl26YPfu3fj6669x7do1BAYG4smTJzrbx8TEYPTo0Rg5ciT279+PSZMmFRrnwoULMXjwYADQOf+nuy8Ls2DBAsTFxWHjxo1YuXIljh8/jhEjRmDQoEGQy+XYunUr3nnnHWzevBkLFizQ2daQ8yAqEkFUjm3YsEEAEKGhodpl48aNEwDEL7/8olO2V69eok6dOtr3mzZtEgDEunXrnnsMAEIul4ukpCSd5d27dxdVqlQRCoVCZ/mUKVOElZVVgfL5cnNzRU5Ojpg4caJo0qSJdvmnn34qAIiUlJRnxnLv3j0BQGzYsEG7bNGiRQKAWLFihU7ZSZMmCSsrK6HRaIQQQuzbt08AEN98841OuWXLlgkAYtGiRc88rhBCHDt2TAAQTZs21e5TCCHu378vLCwsxGuvvSaEEEKtVgtPT0/h7+8v1Gq1tlxqaqpwdXUVgYGBBWKfOXOmzrF++uknAUBs2bJFu+xZMfr4+Ihx48YViPPYsWPPPJfc3FyRlpYmbG1txeeff65dnn89jR07tsA2+evu3bunXda7d2/h4+NToKxSqRR2dnZi+vTpOsvr168vOnbs+My4hBDiwIEDhf48t23bJgCItWvXCiGEyMnJEW5ubmLkyJE65d555x1haWkpEhIShBBChISECABi5cqVOuWioqKEtbW1eOedd7TL2rdvLwCII0eOPDfGfJMnTxbP+ph51s+lT58+OuVmzJghAIhp06bpLO/fv79wdHTUvjfkPIiKii1NVCFJJBL06dNHZ1nDhg11umP++OMPWFlZPbP74WmdOnVC5cqVte+zsrJw5MgRDBgwADY2NsjNzdW+evXqhaysLJw7d05b/tdff0WbNm1QqVIlmJubw8LCAuvXr8eNGze0ZZo3bw4AGDp0KH755Rc8evTIoHPu27dvgfPNyspCXFwcAODEiRPa/T9txIgRBh1n5MiRkEgk2vc+Pj4IDAzEsWPHAAA3b97E48ePMWbMGEil//4JqlSpEgYNGoRz584hIyNDZ5+jRo3SeT906FCYm5tr9/my0tLSMHfuXNSsWRPm5uYwNzdHpUqVkJ6ervMzyDdo0KCXOp6dnR1effVVbNy4Eenp6QCAo0eP4vr165gyZcpzt81vOfpvl+OQIUNga2uLI0eOAADMzc0xevRo7Ny5U9sNq1arsXnzZvTr1w9OTk4AgL1790IikWD06NE616m7uzsaNWpU4C7DypUro1OnTi91/s8TFBSk875evXoAUODmhnr16iEpKUnbRWfoeRAVBZMmqpBsbGxgZWWls0wmkyErK0v7Pj4+Hp6enjof7M/y3y6HxMRE5Obm4ssvv4SFhYXOq1evXgCg7fbZuXMnhg4dCi8vL2zZsgUhISEIDQ3FhAkTdOJp164ddu/ejdzcXIwdOxZVqlSBn58ftm7dqtc5539IPn2+QN5A5vyYzc3N4ejoqFPOzc1Nr/3nc3d3L3RZYmKi9jhAwToDAE9PT2g0GiQnJz93n+bm5nByctLu62WNHDkSa9aswWuvvYaDBw/iwoULCA0NhYuLi7Z+nvaiLiZ9TJ06Fampqfjpp58AAGvWrEGVKlXQr1+/526X/3P676BziUSiU88AtNdQcHAwAODgwYOIiYnR6Zp78uQJhBBwc3MrcK2eO3euQPekMc79ef57/VlaWj53ef7viKHnQVQUvHuO6BlcXFxw+vRpaDSaFyZOT7esAHn/jZuZmWHMmDHPHJ/i6+sLANiyZQt8fX2xbds2nf38d1A6APTr1w/9+vWDSqXCuXPnsGzZMowcORLVqlVD69atDT1FHU5OTsjNzUVSUpLOB1RsbKxB+ymsfGxsrDZpy/8aExNToNzjx48hlUp1Wu3yt/fy8tK+z83NRWJiok4iKJPJCq2zFyVWCoUCe/fuxaJFizBv3jzt8vyxZoX578+7KGrWrImePXviq6++Qs+ePbFnzx4sWbIEZmZmz90u/+cUHx+vkzgJIRAbG6ttkQSA+vXro0WLFtiwYQPefPNNbNiwAZ6enujWrZu2jLOzMyQSCU6dOqVNpJ/232XGOPfiYOh5EBUFW5qInqFnz57Iysoq0kSRNjY26NixIy5fvoyGDRuiWbNmBV75H/gSiQSWlpY6H0axsbGF3j2XTyaToX379tqB64XdnWao9u3bAwC2bdumszy/lUJfW7duhRBC+/7Bgwc4e/YsOnToAACoU6cOvLy88PPPP+uUS09Px44dO7R31D0tvzUm3y+//ILc3FztPoG8u7GuXr2qU+7o0aMF7rD6r/w72v77ofr9999DrVa/8HyfRyaTFdpSlW/69Om4evUqxo0bBzMzM7z++usv3Gfnzp0B5CXbT9uxYwfS09O16/O9+uqrOH/+PE6fPo3ff/9de6x8QUFBEELg0aNHhV6n/v7+hpyyjv+2Zhan4jwPonxsaSJ6hhEjRmDDhg146623cPPmTXTs2BEajQbnz59HvXr1MHz48Odu//nnn+OVV15B27Zt8fbbb6NatWpITU3F7du38fvvv2vHpgQFBWHnzp2YNGkSBg8ejKioKHzwwQfw8PDQubvqvffeQ3R0NDp37owqVaogJSUFn3/+OSwsLLQJz8vo0aMH2rRpg9mzZ0OpVCIgIAAhISHaO/j06aYEgLi4OAwYMACvv/46FAoFFi1aBCsrK8yfP1+7nxUrVmDUqFEICgrCm2++CZVKhU8++QQpKSlYvnx5gX3u3LkT5ubm6Nq1K65du4aFCxeiUaNGOuOvxowZg4ULF+K9995D+/btcf36daxZswZyufy58drb26Ndu3b45JNP4OzsjGrVquHEiRNYv349HBwc9Ky9wvn7+2Pnzp345ptvEBAQAKlUimbNmmnXd+3aFfXr18exY8cwevRouLq6vnCfXbt2Rffu3TF37lwolUq0adMGV69exaJFi9CkSROMGTNGp/yIESMwa9YsjBgxAiqVqsBYqDZt2uCNN97Aq6++iosXL6Jdu3awtbVFTEwMTp8+DX9/f7z99ttFPn8A+Pjjj9GzZ0+YmZmhYcOG2q41YyrO8yDSMt0YdKLi96y752xtbQuUzb9T62mZmZnivffeE7Vq1RKWlpbCyclJdOrUSZw9e1ZbBoCYPHlyoce/d++emDBhgvDy8hIWFhbCxcVFBAYGig8//FCn3PLly0W1atWETCYT9erVE+vWrSsQz969e0XPnj2Fl5eXsLS0FK6urqJXr17i1KlTOsfDM+6ei4+PL7Runr7bKykpSbz66qvCwcFB2NjYiK5du4pz584JADp3kRUm/+6nzZs3i2nTpgkXFxchk8lE27ZtxcWLFwuU3717t2jZsqWwsrIStra2onPnzuLMmTM6ZfJjDwsLE3369BGVKlUSdnZ2YsSIEeLJkyc6ZVUqlXjnnXeEt7e3sLa2Fu3btxdXrlzR6+656OhoMWjQIFG5cmVhZ2cnevToISIiIgpsW9j19KL6HDx4sHBwcBASiaTQO8kWL14sAIhz5849t36flpmZKebOnSt8fHyEhYWF8PDwEG+//bZITk4utPzIkSMFANGmTZtn7vOHH34QLVu2FLa2tsLa2lrUqFFDjB07Vudn1759e9GgQQO941SpVOK1114TLi4u2vPPr59n/Vx+/fVXnX08q86fdV3rcx5ERSUR4qn2cSKi//j5558xatQonDlzBoGBgc8sd/z4cXTs2BG//vqrdn6el7V48WIsWbIE8fHxcHZ2Nso+S5tmzZpBIpEgNDTU1KEQ0Quwe46ItLZu3YpHjx7B398fUqkU586dwyeffIJ27do9N2EiwyiVSkRERGDv3r0ICwvDrl27TB0SEemBSRMRadnZ2SE4OBgffvgh0tPT4eHhgfHjx+PDDz80dWjlyqVLl9CxY0c4OTlh0aJF6N+/v6lDIiI9sHuOiIiISA+ccoCIiIhID0yaiIiIiPTApImIiIhIDxwIDkCj0eDx48ews7MrtY8IICIiIl1CCKSmpur9nNCXxaQJec+78vb2NnUYREREVARRUVGoUqVKsR+HSRPybrMG8ird3t7exNEQERGRPpRKJby9vbWf48WNSRP+fWq3vb09kyYiIqIypqSG1nAgOBEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZVJiWmqEj2eeYkejYiIiOglxaVmYe2Ju/jx5I0SPS6TJiIiIioTniiz8O2JO/j5/EOocjXQ5GhK9PhMmoiIiKhUi1Fk4tvjd7A1NArZuXmJUpOqDnitZV0ErS65OEw6pqlatWqQSCQFXpMnTwYAjB8/vsC6Vq1a6exDpVJh6tSpcHZ2hq2tLfr27Yvo6GhTnA4REREZ0aOUTLy7OxztVxzHjyEPkJ2rQTOfytg8sQV2vh2ItrVcSjQek7Y0hYaGQq1Wa99HRESga9euGDJkiHZZjx49sGHDBu17S0tLnX3MmDEDv//+O4KDg+Hk5ITZs2cjKCgIYWFhMDMzK/6TICIiIqOKSsrANyfu4NeLUchRCwBAC19HzOhcC61rOEEikZgkLpMmTS4uuhni8uXLUaNGDbRv3167TCaTwd3dvdDtFQoF1q9fj82bN6NLly4AgC1btsDb2xuHDx9G9+7diy94IiIiKiBHrYG5VFKkxOZhYga+Pn4b28OikavJS5ZaV3fCtH+SJVMrNWOasrOzsWXLFsyaNUunoo8fPw5XV1c4ODigffv2+Oijj+Dq6goACAsLQ05ODrp166Yt7+npCT8/P5w9e/aZSZNKpYJK9e9tikqlspjOioiIqGJQZuVgwc5w7AuPgQRAJZk57KwsUElmDluZGSpZWcAu/3uZBSpZmaPSP9/bysxwOjIBOy8/gvqfZOmVms6Y1rkWWvg6mvbEnlJqkqbdu3cjJSUF48eP1y7r2bMnhgwZAh8fH9y7dw8LFy5Ep06dEBYWBplMhtjYWFhaWqJy5co6+3Jzc0NsbOwzj7Vs2TIsWbKkuE6FiIioQol4pMCkny7hYVIGAEAAUGblQpmVa/C+2tV2wfTONRHgU3qSpXylJmlav349evbsCU9PT+2yYcOGab/38/NDs2bN4OPjg3379mHgwIHP3JcQ4rnNgvPnz8esWbO075VKJby9vV/yDIiIiCoWIQS2nHuAD/beQLZagyqVrfH58MbwrmyDVFUu0lW5SMvKReo/X9Ozc5GalYu0/Peqf9c5VrLExFd80bRq5Rcf2ERKRdL04MEDHD58GDt37nxuOQ8PD/j4+CAyMhIA4O7ujuzsbCQnJ+u0NsXFxSEwMPCZ+5HJZJDJZMYJnoiIqAJKzcrBvJ3h2Hc1BgDQtb4bPh3cCHIbCwCAqymDKyal4jEqGzZsgKurK3r37v3ccomJiYiKioKHhwcAICAgABYWFjh06JC2TExMDCIiIp6bNBEREVHRXXusQN81Z7DvagzMpRK827se1o4J0CZM5ZXJW5o0Gg02bNiAcePGwdz833DS0tKwePFiDBo0CB4eHrh//z4WLFgAZ2dnDBgwAAAgl8sxceJEzJ49G05OTnB0dMScOXPg7++vvZuOiIiIjEMIga0XorD492vIztXAy8EaX45sUqq71IzJ5EnT4cOH8fDhQ0yYMEFnuZmZGcLDw7Fp0yakpKTAw8MDHTt2xLZt22BnZ6ctt2rVKpibm2Po0KHIzMxE586dsXHjRs7RREREZETpqlws2BWO3648BgB0ruuKlUMbwcHG8gVblh8SIYQwdRCmplQqIZfLoVAoYG9vb+pwiIiISpW/Y5WY9NMl3I1Ph5lUgne618HrbatDKjXNJJP5Svrz2+QtTURERFQ6CSHw68VoLPwtAqpcDdztrbBmZBM0q1b6pgMoCUyaiIiIqICM7Fy8uzsCOy89AgC0r+2CVcMaw9G24nTH/ReTJiIiItJKSFPh6I04rD11F7fj0iCVALO71cHb7WuYvDvO1Jg0ERERVXB34tNw6PoTHLr+BJceJiN/tLOrnQxfjmiCltVN/9y30oBJExERUQWj0QhcjkrGn/8kSnfj03XW+3vJ0aWeG0a3qgqnSpwMOh+TJiIiogogK0eN05EJOHT9CY78/QQJadnadRZmErSq7oRu9d3Qpb4bPOTWJoy09GLSREREVMppNAIPkzKQkKZCrkZA/Z9XrkZAI/75qtH9qspVI+ROIk5FJiAzR63dp52VOTrWcUXX+m5oX8cF9lblezZvY2DSREREVIoIIRCdnImr0QpcfZSC8GgFwh8pkJqV+9L79pRboWt9N3St744Wvo6wNC8VT1MrM5g0ERERmYgQArHKLFyNViA8WoG/olMQ/kiBlIycAmUtzaXwlFvBTCqBuVQKqVQCc6kEZk+/JBKYm0kgleiuq+1mh6713dDA0x4SScW+A+5lMGkiIiIqQfcT0rHr8iOEP1LgarQCCWmqAmUszCSo624P/ypyNPSSw7+KHLXd7GBhxpYhU2LSREREVEJC7iTijU0Xkar6t6stvyUoPzlqWEWOOu52kJnzGaqlDZMmIiKiErA/PAYzgq8gW61BY28HDGjiBf8qctT3sIeVBROksoBJExERUTHbHHIf7+25BiGAHg3csXp4YyZKZRCTJiIiomIihMCqQ7fwxdHbAIBRLavi/X5+MKvgjyMpq5g0ERERFYNctQYLf4vA1gtRAICZXWpjWueavHutDGPSREREFVqOWoPfrjxGHTc7+FeRG2WfWTlqTN16GYeuP4FUAnzQ3w+jWvoYZd9kOkyaiIioQvto3w1sPHsfANC2ljPe7lADras7FblFSJGRg9c2hSL0fjIszaX4YngT9PBzN2LEZCpMmoiIqMI6eC1WmzCZSSU4FZmAU5EJaOztgEkdaqBLPTdIDRh/FKvIwrgfLuDmk1TYWZnj+7HN0LK6UzFFTyWNs2QREVGF9CglE+9svwoAeKNddRyf0wFjW/tAZi7FlagUvLE5DN1Xn8TOS9HIUWteuL/bcakY+PUZ3HySClc7GX59qzUTpnJGIoQQpg7C1JRKJeRyORQKBezt7U0dDhERFbMctQbD155D2INkNPJ2wK9vttY+hy0+VYUNZ+5hc8gD7SSUXg7WeLN9dQxt5l3oVAFhD5Ix8cdQpGTkoLqzLX6c0ALejjYlek4VUUl/fjNpApMmIqKKZsWBv/H18TuwszLH/mltC01wlFk52HLuAX44fQ8JadkAAOdKlni1jS/GtPaBvZUFAODo308w6adLyMrRoJG3AzaMbw5HW8sSPZ+KikmTCTBpIiKqOE5FxmPsDxcgBPD1qKbo5e/x3PJZOWr8ejEK3528i+jkTACAncwco1r5wENuhff3XodaI9C+tgu+Gd0UNpYcLlxSmDSZAJMmIqKKIS41C70+P4WEtGyMalkVHw3w13vbHLUGe68+xjfH7+DWkzSddQObeOHjwQ35QN0SVtKf30yHiYioQlBrBGZuu4KEtGzUdbfDwqD6Bm1vYSbFgCZV0K+RF478HYevj9/G5YcpeLN9dcztXtegu+yobGLSREREFcI3x2/jzO1EWFuYYc3IpkV+9ptUKkHX+m7oUs8Vaapc2P0ztonKP7YjEhFRuRd6PwmfHboFAHi/XwPUdK300vuUSCRMmCoYJk1ERFSuJadnY9rWy9AIYEATLwwOqGLqkKiMYtJERETllhAC/9t+FTGKLPg62+KD/n58YC4VGZMmIiIqtzacuY/DN57A0kyKNSOboJKMQ3mp6Jg0ERFRuRQercCyP24AAP6vdz008JSbOCIq65g0ERFRuZOalYMpWy8hRy3QvYEbxrb2MXVIVA4waSIionJFCIH/2xWBB4kZ8HKwxopBjTiOiYyCSRMREZUrv1yMwp6/HsNMKsEXIxpDbsNpAcg4mDQREVG5cetJKhbtuQYAmN2tNgJ8HE0cEZUnvI2AiIjKNI1G4NpjJU5GxiM49CGycjRoW8sZb7WrYerQqJxh0kRERGVOnDILJyMTcPJWPE7fTkBSerZ2naudDJ8NbcxnwZHRMWkiIqJSLytHjYv3k3EyMh4nb8Xj79hUnfW2lmZoXcMZ7Ws7o6e/B5wryUwUKZVnTJqIiKhYZOdqcOj6E4TeT4KluRTWFmawtjSDjaXZf743L3T545RMnLiV15p0/l4isnI02n1LJIC/lxxtazmjXS0XNPWpDAszDtOl4sWkiYiIjOpOfBq2hUZhR1g0Ep/qNntZrnYytKvtgna1XfBKTWc42loabd9E+mDSRERELy0rR40/ImKw9UIULtxL0i53tZOhl78HLMwkyMhWIzNHjcx/vmZkq5H1z9d/l+VqW5QszaVo6euIdrVc0La2M+q42XG+JTIpJk1ERFRkf8cqEXwhCjsvRUOZlQsAkEqAjnVcMbxFVXSs4wJzA7vNNBqBrFw1zKVSWJqzy41KDyZNRERkkHRVLvZefYytF6JwJSpFu9zLwRrDmntjSLMq8JBbF3n/UqkENpb8eKLSh1clERHpJTxagZ8vPMTvfz1GmiqvVclcKkHX+m4Y3qIqXqnpDDPe5k/lmEnbPatVqwaJRFLgNXnyZAB5zw9avHgxPD09YW1tjQ4dOuDatWs6+1CpVJg6dSqcnZ1ha2uLvn37Ijo62hSnQ0RUbm298BB91pzG1gsPkabKRTUnG8zrWRch8zvjm9EBaF/bhQkTlXsmTZpCQ0MRExOjfR06dAgAMGTIEADAihUr8Nlnn2HNmjUIDQ2Fu7s7unbtitTUf+fnmDFjBnbt2oXg4GCcPn0aaWlpCAoKglqtNsk5ERGVNw8TM/DB3usAgO4N3LD19VY4NqcD3mpfAy52nA+JKg6JEEKYOoh8M2bMwN69exEZGQkA8PT0xIwZMzB37lwAea1Kbm5u+Pjjj/Hmm29CoVDAxcUFmzdvxrBhwwAAjx8/hre3N/bv34/u3bvrdVylUgm5XA6FQgF7e/viOTkiojJIoxEY9f15hNxNREtfR2x9vRVn2qZSo6Q/v0vNbQnZ2dnYsmULJkyYAIlEgnv37iE2NhbdunXTlpHJZGjfvj3Onj0LAAgLC0NOTo5OGU9PT/j5+WnLFEalUkGpVOq8iIiooJ8vPETI3URYWUjx8aCGTJioQis1SdPu3buRkpKC8ePHAwBiY2MBAG5ubjrl3NzctOtiY2NhaWmJypUrP7NMYZYtWwa5XK59eXt7G/FMiIjKh+jkDCzbfwMA8E73uqjmbGviiIhM66WTJrVajStXriA5Ofml9rN+/Xr07NkTnp6eOsv/O5GZEOKFk5u9qMz8+fOhUCi0r6ioqKIHTkRUDgkhMH9nONKz1WjmUxnjA6uZOiQikzM4aZoxYwbWr18PIC9hat++PZo2bQpvb28cP368SEE8ePAAhw8fxmuvvaZd5u7uDgAFWozi4uK0rU/u7u7Izs4ukLA9XaYwMpkM9vb2Oi8iIvrXLxejcCoyATJzKVYMZrccEVCEpGn79u1o1KgRAOD333/HvXv38Pfff2PGjBn4v//7vyIFsWHDBri6uqJ3797aZb6+vnB3d9feUQfkjXs6ceIEAgMDAQABAQGwsLDQKRMTE4OIiAhtGSIiMkyMIhMf7s3rlpvdrTaqu1QycUREpYPBk1smJCRoW4H279+PIUOGoHbt2pg4cSK++OILgwPQaDTYsGEDxo0bB3Pzf8ORSCSYMWMGli5dilq1aqFWrVpYunQpbGxsMHLkSACAXC7HxIkTMXv2bDg5OcHR0RFz5syBv78/unTpYnAsREQVXX63XKoqF429HTDxleqmDomo1DA4aXJzc8P169fh4eGBAwcO4OuvvwYAZGRkwMzMzOAADh8+jIcPH2LChAkF1r3zzjvIzMzEpEmTkJycjJYtW+LPP/+EnZ2dtsyqVatgbm6OoUOHIjMzE507d8bGjRuLFAsRUUW349IjHL8ZD0szKT4Z3JATVhI9xeB5mhYvXozVq1fDw8MDGRkZuHXrFmQyGX744QesW7cOISEhxRVrseE8TUREwBNlFrp+dgLKrFy806MOJnWoaeqQiJ6rpD+/DW5pWrx4Mfz8/BAVFYUhQ4ZAJsubDdbMzAzz5s0zeoBERFT8hBD4v10RUGblomEVOd5oy245ov8qVTOCmwpbmoioovvtyiNMD74CCzMJ9k5tizrudi/eiMjESv2M4NOmTSt0wPeaNWswY8YMY8REREQlKD5VhUV78h6GPrVTLSZMRM9gcNK0Y8cOtGnTpsDywMBAbN++3ShBERFRyRBCYOHuCKRk5KC+hz3e7lDD1CERlVoGJ02JiYmQy+UFltvb2yMhIcEoQRERUcnYFx6DA9diYS6V4JMhDWFhVmqerkVU6hj821GzZk0cOHCgwPI//vgD1atz4CARUVmRmKbCe7/ldctN6lgTDTwL/kNMRP8y+O65WbNmYcqUKYiPj0enTp0AAEeOHMHKlSuxevVqY8dHRETFZNGea0hKz0ZddztM6cjpBYhexOCkacKECVCpVPjoo4/wwQcfAACqVauGb775BmPHjjV6gEREZHwHImKx92oMzKQSfDK4ESzN2S1H9CIvNeVAfHw8rK2tUalS2X4uEaccIKKKJDk9G11XnURCmgqTOtTAOz3qmjokoiIp9ZNbPs3FxcVYcRARUQl5f+91JKSpUNO1EqZ1rmXqcIjKDL2SpqZNm+LIkSOoXLkymjRpAonk2c8iunTpktGCIyIi44lOzsDiPddx+MYTSCXAJ4MbwsqCz+kk0pdeSVO/fv20j0vp379/ccZDRERGlqPW4PtT9/DFkUhk5qhhLpVgfq96aFK1sqlDIypT+BgVcEwTEZVf5+8m4t3dEYiMSwMAtPB1xIf9/VDbjbN+U9lXZsY0Xbx4ETdu3IBEIkG9evUQEBBgzLiIiOglJKapsHT/39hxKRoA4GhriQW96mFQU6/nDrEgomczOGmKjo7GiBEjcObMGTg4OAAAUlJSEBgYiK1bt8Lb29vYMRIRkZ40GoHg0Ch8fOBvKDJzAAAjWlTF3B514GBjaeLoiMo2gyfmmDBhAnJycnDjxg0kJSUhKSkJN27cgBACEydOLI4YiYhID9cfKzH427NYsCsciswc1POwx85JgVg20J8JE5ERGDymydraGmfPnkWTJk10ll+6dAlt2rRBZmamUQMsCRzTRERlWZoqF6sO3cLGs/eh1gjYWpphVrc6GNfaB+Z8lhyVY6V+TFPVqlWRk5NTYHlubi68vLyMEhQREb2YEAJ/RMRiye/X8ESpAgD09vfAwqD6cJdbmTg6ovLH4KRpxYoVmDp1Kr766isEBARAIpHg4sWLmD59Oj799NPiiJGIiP7j+mMllv1xA6ciEwAAPk42WNK3ATrUcTVxZETll8Hdc5UrV0ZGRgZyc3Nhbp6Xc+V/b2trq1M2KSnJeJEWI3bPEVFZEZWUgc8O3cLuK48gBGBpJsVbHWpgUocanKiSKpxS3z23evXqYgiDiIieJyk9G18du43NIQ+QrdYAAPo08sScbrXh42T7gq2JyBgMTprGjRtXHHEQEVEhMrJzseHMfXx7/A5SVbkAgDY1nTCvRz34V5GbODqiiqVIk1uq1Wrs3r1bO7ll/fr10bdvX5iZsWmYiMgYctUa/HIxGqsP30Jcat4g7/oe9pjXsy7a1nLmBJVEJmBw0nT79m306tULjx49Qp06dSCEwK1bt+Dt7Y19+/ahRo0axREnEVGFIITAwWtPsOLg37gbnw4AqFLZGv/rXgd9GnpCKmWyRGQqBg8E79WrF4QQ+Omnn+Do6AgASExMxOjRoyGVSrFv375iCbQ4cSA4EZUGF+4lYdkfN3D5YQqAvEefTO1UEyNbVoXMnC35RP9V6geCnzhxAufOndMmTADg5OSE5cuXo02bNkYNjoioPMvO1eBhUjruxKfj14tROHwjDgBgbWGG19v64vV21WFnZWHiKIkon8FJk0wmQ2pqaoHlaWlpsLTkNP1EVPZoNALRyZm4HqPA9cdKXI9RIjIuDTaW5vCUW8HTwRoeDlbwlFvnfS+3grvcChZ6zLYthEB8qgp34tNxNyENd+PTcTc+DXcT0hGVlAHNU239ZlIJhjf3xvTOteBqz8kpiUobg5OmoKAgvPHGG1i/fj1atGgBADh//jzeeust9O3b1+gBEhEZU1aOGrfj0rTJ0fXHStyIUWrvTPuvGzHKQpdLJICrnQwecmt4/ZNIeTpYw8HGAtHJmdrE6F58+jP3DQC2lmao7lIJDTzt8Ua76qjuUsko50lExmfwmKaUlBSMGzcOv//+Oyws8pqNc3Nz0bdvX2zYsAEODg7FEWex4pgmovLr2mMFQu4kapOk23FpyNUU/LNnaSZFHXc71PewR31Pe9R2s0NWrhoxKVl4nJKJx4pMPE7JRIwiCzEpWdq5kvQhlQBVKtuguostqjtXyvvqYosaLpXgaifjnXBERVTqxzQ5ODjgt99+w+3bt3Hjxg0IIVC/fn3UrFmzOOIjIiqyqKQM9FtzpkCS5GBjgQae9toEqb6HHNVdbPXqbgPyuvMS07MR808i9fifxCpGkYWk9Gx4VbbWJkg1XGxR1cmGA7mJygGDk6b3338fc+bMQc2aNXUSpczMTHzyySd47733jBogEVFRbQ+LRq5GwNfZFgOaeGmTJA+51Uu17kilErjYyeBiJ0PDKg7GC5iISjWDu+fMzMwQExMDV1fdh0ImJibC1dUVarXaqAGWBHbPEZU/Go1A+0+PISopE6uGNcKAJlVMHRIRGVlJf37r1xb9FCFEof+h/fXXXzrTEBARmVLo/SREJWWikswc3Ru4mzocIioH9O6eq1y5MiQSCSQSCWrXrq2TOKnVaqSlpeGtt94qliCJiAy141I0AKCXvztsLIv0xCgiIh16/yVZvXo1hBCYMGEClixZArn83wdFWlpaolq1amjdunWxBElEZIjMbDX2h8cCAAY1ZbccERmH3knTuHHjAAC+vr5o06YNzM35nxsRlU4Hr8UiTZULb0drNK/GYQNEZBwGZz7t27cvjjiIiIwmv2tuYJMqfMAtERmNwQPBiYhKs8cpmTh9OwEAu+aIyLiYNBFRubLr8iMIAbSo5oiqTjamDoeIyhEmTURUbgghtF1zgwK8TBwNEZU3TJqIqNy4EpWCu/HpsLKQope/h6nDIaJyRq+B4AMHDtR7hzt37ixyMERELyO/lal7A3fYWVmYOBoiKm/0SpqenpOJiKg0UuWq8ftfMQCAwQEcAE5ExqdX0rRhw4ZiC+DRo0eYO3cu/vjjD2RmZqJ27dpYv349AgICAADjx4/Hjz/+qLNNy5Ytce7cOe17lUqFOXPmYOvWrcjMzETnzp3x9ddfo0oV/uEkqiiO3IiDIjMH7vZWCKzhbOpwiKgcMumYpuTkZLRp0wYWFhb4448/cP36daxcuRIODg465Xr06IGYmBjta//+/TrrZ8yYgV27diE4OBinT59GWloagoKCyuTDg4moaHaE5XXNDWjqBTPOzURExUCvlqYmTZoU+pDewly6dEnvg3/88cfw9vbWacmqVq1agXIymQzu7oU/cFOhUGD9+vXYvHkzunTpAgDYsmULvL29cfjwYXTv3l3veIiobIpPVeH4rXgAnJuJiIqPXklT//79i+Xge/bsQffu3TFkyBCcOHECXl5emDRpEl5//XWdcsePH4erqyscHBzQvn17fPTRR3B1dQUAhIWFIScnB926ddOW9/T0hJ+fH86ePVto0qRSqaBSqbTvlUplsZwfEZWM3648gloj0MjbATVdK5k6HCIqp/RKmhYtWlQsB7979y6++eYbzJo1CwsWLMCFCxcwbdo0yGQyjB07FgDQs2dPDBkyBD4+Prh37x4WLlyITp06ISwsDDKZDLGxsbC0tETlypV19u3m5obY2NhCj7ts2TIsWbKkWM6JiErejkuPAACDm3JuJiIqPiZ96q5Go0GzZs2wdOlSAHndgNeuXcM333yjTZqGDRumLe/n54dmzZrBx8cH+/bte+5UCEKIZ3Ypzp8/H7NmzdK+VyqV8Pb2NsYpEVEJu/5YiRsxSliaSdGnkaepwyGicszggeBqtRqffvopWrRoAXd3dzg6Ouq8DOHh4YH69evrLKtXrx4ePnz43G18fHwQGRkJAHB3d0d2djaSk5N1ysXFxcHNza3QfchkMtjb2+u8iKhsyp+bqXM9VzjYWJo4GiIqzwxOmpYsWYLPPvsMQ4cOhUKhwKxZszBw4EBIpVIsXrzYoH21adMGN2/e1Fl269Yt+Pj4PHObxMREREVFwcMjb7bfgIAAWFhY4NChQ9oyMTExiIiIQGBgoEHxEFHZkqPW4LcreV1zHABORMXN4KTpp59+wrp16zBnzhyYm5tjxIgR+P777/Hee+/pzJ2kj5kzZ+LcuXNYunQpbt++jZ9//hlr167F5MmTAQBpaWmYM2cOQkJCcP/+fRw/fhx9+vSBs7MzBgwYACBv4s2JEydi9uzZOHLkCC5fvozRo0fD399fezcdEZVPJ27GIyEtG062lmhfx8XU4RBROWdw0hQbGwt/f38AQKVKlaBQKAAAQUFB2Ldvn0H7at68OXbt2oWtW7fCz88PH3zwAVavXo1Ro0YBAMzMzBAeHo5+/fqhdu3aGDduHGrXro2QkBDY2dlp97Nq1Sr0798fQ4cORZs2bWBjY4Pff/8dZmZmhp4eEZUh+V1z/Zt4wcKMj9IkouJl8EDwKlWqICYmBlWrVkXNmjXx559/omnTpggNDYVMJjM4gKCgIAQFBRW6ztraGgcPHnzhPqysrPDll1/iyy+/NPj4RFQ2pWRk48iNOADsmiOikmHwv2YDBgzAkSNHAADTp0/HwoULUatWLYwdOxYTJkwweoBERIX5/a/HyFZrUM/DHvU9eTMHERU/g1uali9frv1+8ODB8Pb2xpkzZ1CzZk307dvXqMERET3L9kv5A8A5NxMRlYyXnqepZcuWaNmypTFiISLSy+24NPwVlQIzqQT9GjNpIqKSwZGTRFTm5A8A71DbBS52ho+lJCIqCiZNRFSmqDUCu/K75gI4AJyISg6TJiIqU87eSUCsMgtyawt0rudq6nCIqALRK2n64osvkJWVBQB4+PAhhBDFGhQR0bPsCMvrmuvTyAMyc87FRkQlR6+kadasWVAqlQAAX19fxMfHF2tQRESFSc3KwYFrsQCAwQF8yDYRlSy97p7z9PTEjh070KtXLwghEB0drW15+q+qVasaNUAionx/hMciK0eDGi62aFRFbupwiKiC0StpevfddzF16lRMmTIFEokEzZs3L1BGCAGJRAK1Wm30IImIAGD7P3fNDQqoAolEYuJoiKii0StpeuONNzBixAg8ePAADRs2xOHDh+Hk5FTcsRERaT1MzMCFe0mQSIABTTg3ExGVPL0nt7Szs4Ofnx82bNiANm3aFOk5c0RERZU/N9MrNZ3hIbc2cTREVBEZPCP4uHHjAABhYWG4ceMGJBIJ6tWrh6ZNmxo9OCKizGw11p++i3Wn7gLgw3mJyHQMTpri4uIwfPhwHD9+HA4ODhBCQKFQoGPHjggODoaLi0txxElEFYxaI7AjLBorD93EE6UKANCimiN6+LmbODIiqqgMntxy6tSpUCqVuHbtGpKSkpCcnIyIiAgolUpMmzatOGIkogpECIFjf8eh1+en8M6Oq3iiVKFKZWt8Prwxgt9oBSsLzs1ERKYhEQbOVCmXy3H48OECd9BduHAB3bp1Q0pKijHjKxFKpRJyuRwKhQL29vamDoeowgqPVmDZHzdw9k4iAEBubYGpnWpiTGsfTmRJRAWU9Oe3wd1zGo0GFhYWBZZbWFhAo9EYJSgiqliikjLw6Z838duVxwAAS3MpXg2shkkdakJuU/DvDRGRKRicNHXq1AnTp0/H1q1b4enpCQB49OgRZs6cic6dOxs9QCIqv1IysvHVsdv48ewDZKvz/uka0MQLs7vVRpXKNiaOjohIl8FJ05o1a9CvXz9Uq1YN3t7ekEgkePjwIfz9/bFly5biiJGIypmsHDU2hdzHmqO3oczKBQC0qemE+T3rwc+LM30TUelkcNLk7e2NS5cu4dChQ/j7778hhED9+vXRpUuX4oiPiMqZQ9efYPGea3iUkgkAqOtuh3k966J9bRfO8k1EpZrBA8HLIw4EJyp+6apcfLD3OoJDowAA7vZWmNWtNgY1rQIzKZMlIjJcqR8ITkRkqEsPkzFz2xU8SMyARAK80bY6ZnSpDWtL3hFHRGUHkyYiKja5ag2+PHoba47dhloj4OVgjZVDG6FVdT67kojKHiZNRFQs7iWkY+a2K7gSlQIA6N/YE0v6+UFuzSkEiKhsYtJEREYlhMC20Ci8v/c6MrLVsLMyx4f9/dCvsZepQyMieikGP0alQ4cO2LRpEzIzM4sjHiIqwxLTVHh9Uxjm7QxHRrYaras74eCMdkyYiKhcMDhpCggIwDvvvAN3d3e8/vrrOHfuXHHERURlzLG/49B99SkcvvEElmZS/F+vevjptZbwdLA2dWhEREZhcNK0cuVKPHr0CJs2bUJ8fDzatWuH+vXr49NPP8WTJ0+KI0YiKsUys9VYuDsCr24MRUKaCrXdKmH35DZ4vV11SDmVABGVIy89T1N8fDy+++47fPTRR1Cr1ejVqxemTZuGTp06GSvGYsd5moiKJjxagenbLuNufDoAYOIrvvhf9zqwsuBUAkRU/MrUPE0XLlzAhg0bsHXrVri6umL8+PGIiYlBnz598Pbbb+PTTz81VpxEVIpkZOdizdHbWHvyLnI1Am72Mqwc0hiv1HI2dWhERMXG4KQpLi4OmzdvxoYNGxAZGYk+ffogODgY3bt31z4CYejQoejfvz+TJqJyRgiBg9ee4IO917WPQent74GPBvjBwcbSxNERERUvg5OmKlWqoEaNGpgwYQLGjx8PFxeXAmVatGiB5s2bGyVAIiodHiSmY9Geazh+Mx4A4OVgjcV9G6BrfTcTR0ZEVDIMTpqOHDmCtm3bPreMvb09jh07VuSgiKj0yMpR49sTd/D18TvIztXA0kyKN9pVx+SONfkYFCKqUAy+e27RokVISUkpsFypVJapwd9E9GLH/o5Dt1UnsfpwJLJzNWhbyxkHZrTFnO51mDARUYVjcEvTiRMnkJ2dXWB5VlYWTp06ZZSgiMi0opMz8P7v1/Hn9bxpRNztrbAwqD56+btrxy4SEVU0eidNV69eBZA3EPT69euIjY3VrlOr1Thw4AC8vDjrL1FZlp2rwfen7+KLI5HIytHAXCrBhFd8Ma1zLVSS8alLRFSx6f1XsHHjxpBIJJBIJIV2w1lbW+PLL780anBEVHLO3k7Awt8icOefOZda+Driw/5+qO1mZ+LIiIhKB72Tpnv37kEIgerVq+PChQs6d81ZWlrC1dUVZmYc40BU1mTlqDFvx1XsvvIYAOBcyRILetXDgCZe7IojInqK3kmTj48PAECj0RRbMERU8j45eBO7rzyGVAKMbV0NM7vWhtzawtRhERGVOnolTXv27EHPnj1hYWGBPXv2PLds3759jRIYERW/M7cTsP70PQDAd2Oacc4lIqLn0Ctp6t+/P2JjY+Hq6or+/fs/s5xEIoFarTZWbERUjBSZOZjz618AgFEtqzJhIiJ6Ab2Spqe75Ng9R1Q+LPotAjGKLFRzssH/9a5n6nCIiEo9gya3zMnJQceOHXHr1q3iioeISsDvfz3G7iuPYSaVYNWwxrCx5HQCREQvYlDSZGFhgYiICKPeUfPo0SOMHj0aTk5OsLGxQePGjREWFqZdL4TA4sWL4enpCWtra3To0AHXrl3T2YdKpcLUqVPh7OwMW1tb9O3bF9HR0UaLkag8iVVk4d3dEQCAyR1roknVyiaOiIiobDD4MSpjx47F+vXrjXLw5ORktGnTBhYWFvjjjz9w/fp1rFy5Eg4ODtoyK1aswGeffYY1a9YgNDQU7u7u6Nq1K1JTU7VlZsyYgV27diE4OBinT59GWloagoKCOL6K6D80GoH/bf8LiswcNKwix9RONU0dEhFRmSERQghDNpg6dSo2bdqEmjVrolmzZrC1tdVZ/9lnn+m9r3nz5uHMmTPPfPyKEAKenp6YMWMG5s6dCyCvVcnNzQ0ff/wx3nzzTSgUCri4uGDz5s0YNmwYAODx48fw9vbG/v370b179xfGoVQqIZfLoVAoYG9vr3f8RGXNj2fvY9Gea7CykGLftLao4VLJ1CERERVZSX9+G9zSFBERgaZNm8Le3h63bt3C5cuXta8rV64YtK89e/agWbNmGDJkCFxdXdGkSROsW7dOu/7evXuIjY1Ft27dtMtkMhnat2+Ps2fPAgDCwsKQk5OjU8bT0xN+fn7aMv+lUqmgVCp1XkTl3e24NCzdfwMAsKBXPSZMREQGMnj057Fjx4x28Lt37+Kbb77BrFmzsGDBAly4cAHTpk2DTCbD2LFjtc+3c3PTvRXazc0NDx48AADExsbC0tISlStXLlDm6efjPW3ZsmVYsmSJ0c6DqLTLUWswc9sVqHI1aFfbBWNa+Zg6JCKiMsfgliZj0mg0aNq0KZYuXYomTZrgzTffxOuvv45vvvlGp9x/B54LIV44GP15ZebPnw+FQqF9RUVFvdyJEJVyXx6JRPgjBeTWFvhkcEM+HoWIqAiKdJ9xaGgofv31Vzx8+BDZ2dk663bu3Kn3fjw8PFC/fn2dZfXq1cOOHTsAAO7u7gDyWpM8PDy0ZeLi4rStT+7u7sjOzkZycrJOa1NcXBwCAwMLPa5MJoNMJtM7TqKy7NLDZKw5dhsAsHSAP9zsrUwcERFR2WRwS1NwcDDatGmD69evY9euXcjJycH169dx9OhRyOVyg/bVpk0b3Lx5U2fZrVu3tM+58/X1hbu7Ow4dOqRdn52djRMnTmgTooCAAFhYWOiUiYmJQURExDOTJqKKIl2Vi1nbrkAjgAFNvNC7oceLNyIiokIZ3NK0dOlSrFq1CpMnT4adnR0+//xz+Pr64s0339RpDdLHzJkzERgYiKVLl2Lo0KG4cOEC1q5di7Vr1wLI65abMWMGli5dilq1aqFWrVpYunQpbGxsMHLkSACAXC7HxIkTMXv2bDg5OcHR0RFz5syBv78/unTpYujpEZUrH+67gfuJGfBysMaSfg1MHQ4RUdkmDGRjYyPu3bsnhBDCyclJXL16VQghxPXr14W7u7uhuxO///678PPzEzKZTNStW1esXbtWZ71GoxGLFi0S7u7uQiaTiXbt2onw8HCdMpmZmWLKlCnC0dFRWFtbi6CgIPHw4UO9Y1AoFAKAUCgUBsdPVFodvh4rfObuFdXm7RVnbyeYOhwiIqMr6c9vg+dpyp//yN/fH40aNcK8efMwYsQIhISEoEePHlAoFMWT3RUjztNE5U1imgrdV59EQlo2Xm/ri//rXf/FGxERlTEl/fltcPdc27ZtcejQIfj7+2Po0KGYPn06jh49ikOHDqFz587FESMRGUAIgfk7w5GQlo06bnaY3a2OqUMiIioXDE6a1qxZg6ysLAB5t+5bWFjg9OnTGDhwIBYuXGj0AInIML+GRePP609gYZb3MF4rCzNTh0REVC4Y3D1XHrF7jsqLqKQM9Fh9EunZaszrWRdvta9h6pCIiIpNqeyeM+QxI0w6iExDoxGY/ctfSM9Wo0U1R7zetrqpQyIiKlf0SpocHBz0noFbrVYbJTAiMsyvYVG4cD8JtpZmWDm0EcyknPWbiMiY9EqajPm8OSIyvuT0bCz/428AwMyuteHtaGPiiIiIyh+9kqb27dsXdxxE9BJWHLyJ5Iwc1HGzw7jAaqYOh4ioXDL47rmTJ08+d327du2KHAwRGe5KVAqCQx8CAD7o7wcLM5M+h5uIqNwyOGnq0KFDgWVPj3fimCaikqPWCCzcHQEhgIFNvdDC19HUIRERlVsG/0uanJys84qLi8OBAwfQvHlz/Pnnn8URIxE9w88XHiL8kQJ2VuaY37OeqcMhIirXDG5pksvlBZZ17doVMpkMM2fORFhYmFECI6LnS0hT4ZMDeYO/53SrAxc7mYkjIiIq34w2+MHFxQU3b9401u6I6AU+/uNvKLNy0cDTHqNb+Zg6HCKics/glqarV6/qvBdCICYmBsuXL0ejRo2MFhgRPdvF+0n4NSwaQN7gb87JRERU/AxOmho3bgyJRIL/Pn2lVatW+OGHH4wWGBEVLletwbu7IwAAw5p5o2nVyiaOiIioYjA4abp3757Oe6lUChcXF1hZWRktKCJ6tk0hD/B3bCocbCwwt2ddU4dDRFRhGJw0+fhw7ASRqcQps7Dq0C0AwDvd68LR1tLEERERVRxFGgh+5MgRBAUFoUaNGqhZsyaCgoJw+PBhY8dGRP+xdP8NpKpy0cjbAcObe5s6HCKiCsXgpGnNmjXo0aMH7OzsMH36dEybNg329vbo1asX1qxZUxwxEhGAkDuJ2H3lMSQS4IN+DSDl4G8iohIlEf8d0f0CXl5emD9/PqZMmaKz/KuvvsJHH32Ex48fGzXAkqBUKiGXy6FQKGBvb2/qcIgKyFFr0OvzU4iMS8PoVlXxYX9/U4dERGRyJf35bXBLk1KpRI8ePQos79atG5RKpVGCIiJdG87cQ2RcGhxtLfG/bhz8TURkCgYnTX379sWuXbsKLP/tt9/Qp08fowRFRP+KUWRi9eFIAMC8nnUht7EwcURERBWTwXfP1atXDx999BGOHz+O1q1bAwDOnTuHM2fOYPbs2fjiiy+0ZadNm2a8SIkqqA/33kBGthoBPpUxuGkVU4dDRFRhGTymydfXV78dSyS4e/dukYIqaRzTRKXVyVvxGPvDBUglwN6pbVHfk9cnEVG+kv78funJLYmoeKhy1Vi85xoAYFxgNSZMREQm9lIP7BVCFHicChEZx/en7uFuQjpc7GSY2bW2qcMhIqrwipQ0bdq0Cf7+/rC2toa1tTUaNmyIzZs3Gzs2ogorKikDXx7NG/z9f73qwd6Kg7+JiEzN4O65zz77DAsXLsSUKVPQpk0bCCFw5swZvPXWW0hISMDMmTOLI06iCmXZHzeQlaNBS19H9GvsaepwiIgIRUiavvzyS3zzzTcYO3asdlm/fv3QoEEDLF68mEkT0Uu6GZuK/eGxkEiA9/v5QSLhzN9ERKWBwd1zMTExCAwMLLA8MDAQMTExRgmKqCJbc+w2AKCXvwfquNuZOBoiIspncNJUs2ZN/PLLLwWWb9u2DbVq1TJKUEQV1Z34NOy9mvcooikda5o4GiIieprB3XNLlizBsGHDcPLkSbRp0wYSiQSnT5/GkSNHCk2miEh/3xy/AyGALvXcUM+DUwwQEZUmBrc0DRo0COfPn4ezszN2796NnTt3wtnZGRcuXMCAAQOKI0aiCiEqKQO7Lj8CAEzpxFYmIqLSxuCWJgAICAjAli1bjB0LUYX27Yk7UGsE2tZyRmNvB1OHQ0RE/1GkpEmtVmPXrl24ceMGJBIJ6tWrh379+sHcvEi7I6rwYhVZ+PViNABgaieODSQiKo0MznIiIiLQr18/xMbGok6dOgCAW7duwcXFBXv27IG/v7/RgyQq7747eQfZag1a+Dqiha+jqcMhIqJCGDym6bXXXkODBg0QHR2NS5cu4dKlS4iKikLDhg3xxhtvFEeMROVafKoKWy88BABMYysTEVGpZXBL019//YWLFy+icuXK2mWVK1fGRx99hObNmxs1OKKKYP3pe8jK0aCxtwPa1HQydThERPQMBrc01alTB0+ePCmwPC4uDjVr8o4fIkOkZGRjc8h9AMDUTjU5+zcRUSlmcNK0dOlSTJs2Ddu3b0d0dDSio6Oxfft2zJgxAx9//DGUSqX2RUTPt+HMfaRnq1HPwx6d6rqaOhwiInoOiRBCGLKBVPpvnpX/X3H+Lp5+L5FIoFarjRVnsVIqlZDL5VAoFLC354SCVDJSs3LQZvlRKLNy8fWopujl72HqkIiIypSS/vw2eEzTsWPHiiMOogpnU8gDKLNyUdO1Eno0cDd1OERE9AIGJ03t27cvjjiIKpSM7FysP30PQN4z5qRSjmUiIirtDB7TREQv7+fzD5GUng0fJxsENWS3HBFRWWDSpGnx4sWQSCQ6L3f3f7spxo8fX2B9q1atdPahUqkwdepUODs7w9bWFn379kV0dHRJnwqR3rJy1Fh78i4AYFKHGjA34/8uRERlgcn/Wjdo0AAxMTHaV3h4uM76Hj166Kzfv3+/zvoZM2Zg165dCA4OxunTp5GWloagoKAyMwidKp5fL0YhLlUFT7kVBjSpYupwiIhITyZ/WJy5ublO69J/yWSyZ65XKBRYv349Nm/ejC5dugAAtmzZAm9vbxw+fBjdu3cvlpiJiio7V4NvT+S1Mr3VoQYszU3+fwsREempSH+xc3NzcfjwYXz33XdITU0FADx+/BhpaWkG7ysyMhKenp7w9fXF8OHDcffuXZ31x48fh6urK2rXro3XX38dcXFx2nVhYWHIyclBt27dtMs8PT3h5+eHs2fPPvOYKpVKZz4pzilFJWX35Ud4lJIJFzsZhjbzNnU4RERkAIOTpgcPHsDf3x/9+vXD5MmTER8fDwBYsWIF5syZY9C+WrZsiU2bNuHgwYNYt24dYmNjERgYiMTERABAz5498dNPP+Ho0aNYuXIlQkND0alTJ6hUKgBAbGwsLC0tdR7pAgBubm6IjY195nGXLVsGuVyufXl788OLil+uWoOvj98GALzRtjqsLMxMHBERERnC4KRp+vTpaNasGZKTk2Ftba1dPmDAABw5csSgffXs2RODBg2Cv78/unTpgn379gEAfvzxRwDAsGHD0Lt3b/j5+aFPnz74448/cOvWLW25Z8mfXPNZ5s+fD4VCoX1FRUUZFDdRUewLj8H9xAxUtrHAqFZVTR0OEREZyOAxTadPn8aZM2dgaWmps9zHxwePHj16qWBsbW3h7++PyMjIQtd7eHjAx8dHu97d3R3Z2dlITk7WaW2Ki4tDYGDgM48jk8kgk8leKlYiQ2g0AmuO5rUyvda2OmwsTT6ckIiIDGRwS5NGoyn0zrTo6GjY2dm9VDAqlQo3btyAh0fh89YkJiYiKipKuz4gIAAWFhY4dOiQtkxMTAwiIiKemzQRlbSD12IRGZcGOytzjGntY+pwiIioCAxOmrp27YrVq1dr30skEqSlpWHRokXo1auXQfuaM2cOTpw4gXv37uH8+fMYPHgwlEolxo0bh7S0NMyZMwchISG4f/8+jh8/jj59+sDZ2RkDBgwAAMjlckycOBGzZ8/GkSNHcPnyZYwePVrb3UdUGggh8OU/rUyvBlaDvZWFiSMiIqKiMLiPYNWqVejYsSPq16+PrKwsjBw5EpGRkXB2dsbWrVsN2ld0dDRGjBiBhIQEuLi4oFWrVjh37hx8fHyQmZmJ8PBwbNq0CSkpKfDw8EDHjh2xbds2nRatVatWwdzcHEOHDkVmZiY6d+6MjRs3wsyMg2ypdDh2Mw7XY5SwsTTDq218TR0OEREVkUQIIQzdKDMzE1u3bsWlS5eg0WjQtGlTjBo1SmdgeFlS0k9JpopDCIEBX5/FlagUvNmuOub3qmfqkIiIyo2S/vwuUtJU3jBpouJy5nYCRn1/HjJzKU7P7QQXO96AQERkLCX9+W1w99yePXsKXS6RSGBlZYWaNWvC15ddEEQA8P2pvMlaR7SoyoSJiKiMMzhp6t+/PyQSCf7bQJW/TCKR4JVXXsHu3bsLTDpJVJFEJ2fg+K28yV/HBVYzbTBERPTSDL577tChQ2jevDkOHTqknRzy0KFDaNGiBfbu3YuTJ08iMTHR4NnBicqbbaFREAIIrOEEX2dbU4dDREQvyeCWpunTp2Pt2rU68yB17twZVlZWeOONN3Dt2jWsXr0aEyZMMGqgRGVJjlqDbaF5M82PbMnZv4mIygODW5ru3LlT6GAre3t77cN2a9WqhYSEhJePjqiMOnIjDnGpKjhXskS3+u6mDoeIiIzA4KQpICAA//vf/7QP6gWA+Ph4vPPOO2jevDkAIDIyElWqVDFelERlzNYLDwEAgwO8YWlu8K8ZERGVQgZ3z61fvx79+vVDlSpV4O3tDYlEgocPH6J69er47bffAABpaWlYuHCh0YMlKguikjJwMjLvn4oRLbxNHA0RERmLwUlTnTp1cOPGDRw8eBC3bt2CEAJ169ZF165dIZXm/Ufdv39/Y8dJVGYEhz6EEEDbWs7wceIAcCKi8qJIj1qXSCTo0aMHevToYex4iMq0HLUGv1yMBpA3NxMREZUfRUqa0tPTceLECTx8+BDZ2dk666ZNm2aUwIjKosPXnyA+VQXnSjJ0re9m6nCIiMiIDE6aLl++jF69eiEjIwPp6elwdHREQkICbGxs4OrqyqSJKrSf/xkAPrRZFViYcQA4EVF5YvBf9ZkzZ6JPnz5ISkqCtbU1zp07hwcPHiAgIACffvppccRIVCY8SEzHqcgESCTsmiMiKo8MTpquXLmC2bNnw8zMDGZmZlCpVPD29saKFSuwYMGC4oiRqEzYeiFvMsu2tVzg7Whj4miIiMjYDE6aLCwsIJFIAABubm54+DCvO0Iul2u/J6posnM12B72zwzgbGUiIiqXDB7T1KRJE1y8eBG1a9dGx44d8d577yEhIQGbN2+Gv79/ccRIVOr9eT0WCWnZcLWToXM9V1OHQ0RExcDglqalS5fCw8MDAPDBBx/AyckJb7/9NuLi4rB27VqjB0hUFuTPAD6suTcHgBMRlVMGtTQJIeDi4oIGDRoAAFxcXLB///5iCYyorLifkI4ztxMhkeQlTUREVD4Z9C+xEAK1atVCdHR0ccVDVObktzJ1qO2CKpU5AJyIqLwyKGmSSqWoVasWEhMTiyseojJFlavGr2GcAZyIqCIwePDFihUr8L///Q8RERHFEQ9RmXLw2hMkpWfD3d4KnepyADgRUXlm8N1zo0ePRkZGBho1agRLS0tYW1vrrE9KSjJacESl3c/nHwAAhjb3hjkHgBMRlWsGJ02rV68uhjCIyp478Wk4dzcJUgkwnAPAiYjKPYOTpnHjxhVHHERlztbzeQPAO9ZxhaeD9QtKExFRWVek/oQ7d+7g3XffxYgRIxAXFwcAOHDgAK5du2bU4IhKq6wcNbZfyhsAPrIlB4ATEVUEBidNJ06cgL+/P86fP4+dO3ciLS0NAHD16lUsWrTI6AESlUYHr8UiJSMHnnIrdKjDAeBERBWBwUnTvHnz8OGHH+LQoUOwtLTULu/YsSNCQkKMGhxRafXT+fwZwKvCTCoxcTRERFQSDE6awsPDMWDAgALLXVxcOH8TVQi341Jx4V7eAHDOAE5EVHEYnDQ5ODggJiamwPLLly/Dy8vLKEERlWY/n48CAHSq6wZ3uZWJoyEiopJicNI0cuRIzJ07F7GxsZBIJNBoNDhz5gzmzJmDsWPHFkeMRKVGVo4aO/4ZAD6KA8CJiCoUg5Omjz76CFWrVoWXlxfS0tJQv359tGvXDoGBgXj33XeLI0aiUmN/eAwUmTnwcrBGu9oupg6HiIhKkMHzNFlYWOCnn37C+++/j8uXL0Oj0aBJkyaoVatWccRHVKr8/M8A8OHNvTkAnIiogjE4aTpx4gTat2+PGjVqoEaNGsURE1GpdOtJKi4+SIaZVIKhHABORFThGNw917VrV1StWhXz5s3jQ3upQslvZepSzxVu9hwATkRU0RicND1+/BjvvPMOTp06hYYNG6Jhw4ZYsWIFoqOjiyM+olIhM/vfAeAjW/qYOBoiIjIFg5MmZ2dnTJkyBWfOnMGdO3cwbNgwbNq0CdWqVUOnTp2KI0Yik9sXHoPUrFx4O1qjbU1nU4dDREQmUKRnz+Xz9fXFvHnzsHz5cvj7++PEiRPGiouoVNkW+s8M4M28IeUAcCKiCqnISdOZM2cwadIkeHh4YOTIkWjQoAH27t1rzNiISoXbcWkIvZ8MqQQY0owDwImIKiqD755bsGABtm7disePH6NLly5YvXo1+vfvDxsbm+KIj8jkfrmYPwM4B4ATEVVkBidNx48fx5w5czBs2DA4O+uO7bhy5QoaN25srNiITC47V4MdYXkDwIc15wzgREQVmcFJ09mzZ3XeKxQK/PTTT/j+++/x119/Qa1WGy04IlM7cuMJEtOz4WonQ8c6nAGciKgiK/KYpqNHj2L06NHw8PDAl19+iV69euHixYvGjI3I5LaG5nXNDWlWBeZmL3XfBBERlXEGtTRFR0dj48aN+OGHH5Ceno6hQ4ciJycHO3bsQP369YsrRiKTiE7OwKnIeADAUA4AJyKq8PT+17lXr16oX78+rl+/ji+//BKPHz/Gl19++VIHX7x4MSQSic7L3d1du14IgcWLF8PT0xPW1tbo0KEDrl27prMPlUqFqVOnwtnZGba2tujbty8n2iSj+PViNIQAAms4wcfJ1tThEBGRiemdNP3555947bXXsGTJEvTu3RtmZmZGCaBBgwaIiYnRvsLDw7XrVqxYgc8++wxr1qxBaGgo3N3d0bVrV6SmpmrLzJgxA7t27UJwcDBOnz6NtLQ0BAUFcWwVvRS1RuDXf+6aG8bnzBEREQxImk6dOoXU1FQ0a9YMLVu2xJo1axAfH//SAZibm8Pd3V37cnHJG2wrhMDq1avxf//3fxg4cCD8/Pzw448/IiMjAz///DOAvEHo69evx8qVK9GlSxc0adIEW7ZsQXh4OA4fPvzSsVHFdSoyHo8VWXCwsUD3Bu4v3oCIiMo9vZOm1q1bY926dYiJicGbb76J4OBgeHl5QaPR4NChQzqtP4aIjIyEp6cnfH19MXz4cNy9excAcO/ePcTGxqJbt27asjKZDO3bt9fewRcWFoacnBydMp6envDz8ytwl9/TVCoVlEqlzovoadv+GQA+oIkXrCyM06pKRERlm8G3A9nY2GDChAk4ffo0wsPDMXv2bCxfvhyurq7o27evQftq2bIlNm3ahIMHD2LdunWIjY1FYGAgEhMTERsbCwBwc3PT2cbNzU27LjY2FpaWlqhcufIzyxRm2bJlkMvl2pe3N7tf6F/xqSocuv4EALvmiIjoXy91D3WdOnWwYsUKREdHY+vWrQZv37NnTwwaNAj+/v7o0qUL9u3bBwD48ccftWUkEt3nfAkhCiz7rxeVmT9/PhQKhfYVFRVlcOxUfu28FI1cjUBjbwfUdbc3dThERFRKGGXiGTMzM/Tv3x979ux5qf3Y2trC398fkZGR2rvo/ttiFBcXp219cnd3R3Z2NpKTk59ZpjAymQz29vY6LyIgL+HO75obzlYmIiJ6SqmarU+lUuHGjRvw8PCAr68v3N3dcejQIe367OxsnDhxAoGBgQCAgIAAWFhY6JSJiYlBRESEtgyRIULvJ+NuQjpsLc3Qp5GnqcMhIqJSxODHqBjTnDlz0KdPH1StWhVxcXH48MMPoVQqMW7cOEgkEsyYMQNLly5FrVq1UKtWLSxduhQ2NjYYOXIkAEAul2PixImYPXs2nJyc4OjoiDlz5mi7+4gMFRz6EADQp5EnbGUm/fUgIqJSxqSfCtHR0RgxYgQSEhLg4uKCVq1a4dy5c/Dx8QEAvPPOO8jMzMSkSZOQnJyMli1b4s8//4SdnZ12H6tWrYK5uTmGDh2KzMxMdO7cGRs3bjTaPFJUcSgyc7A/PAYAB4ATEVFBEiGEMHUQpqZUKiGXy6FQKDi+qQLbHHIfC3+7hjpudjgwo+0LbzggIiLTKunP71I1ponIlIJD/50BnAkTERH9F5MmIgARjxS49lgJS3MpBjb1MnU4RERUCjFpIsK/A8B7NHCHg42liaMhIqLSiEkTVXiZ2Wr8dvkxAM7NREREz8akiSq8/eExSFXloqqjDVpVdzJ1OEREVEoxaaIKL79rblhzb0ilHABORESFY9JEFdrtuDSE3k+GmVSCwQFVTB0OERGVYkyayKgys9WmDsEgv1zMm2agYx1XuNlbmTgaIiIqzZg0kVEos3Lwzva/UH/RAczcdgVZOaU/ecrO1WBHWDQADgAnIqIX48O16KWduBWPeTuuIkaRBQDYdfkRopIy8N2YADhVkpk4umc7cuMJEtOz4WonQ4c6LqYOh4iISjm2NFGRpWblYN6Oqxj3wwXEKLLg42SDxX3qw87KHBcfJGPA12dxOy7N1GE+U/4M4EOaVYG5GX8ViIjo+fhJQUVyKjIe3Ved1CYe4wOr4Y/pbTG+jS92TQqEt6M1HiZlYODXZ3DmdoKJoy0oOjkDJyPjAQDDmlU1cTRERFQWMGkig6Rm5WD+znCMWX8BjxVZqOpog+A3WmFx3wawsczr7a3paofdk9ogwKcylFm5GPfDBWz757b+0uLXi9EQAmhT0wlVnWxMHQ4REZUBTJpIb6cjE9Bj9SlsvZCXAI1r7YMDM9oWOiGkUyUZfnqtJfo08kSuRmDujnAs/+NvaDSipMMuQK0R+PVi/sN52cpERET64UBweqE0VS6W7b+Bn87nJUtVKltjxeCGCKzh/NztrCzM8MXwxvB1tsUXRyLx7Yk7eJCYjs+GNoa1pVlJhF6oU5HxeKzIgoONBbrVdzNZHEREVLYwaaLnOns7Af/bfhWPUjIBAGNa+WBez7qwlel36UgkEszqWhu+zjaYuz0cf0TE4nFKCNaNbQZXE82LtO2fcVgDmnjBysJ0yRsREZUtTJqoUOmqXCz/429sPvcAAODlYI1PBjdEYM3nty49y4AmVeDlYIM3N1/EX9EK9P/qDH54tTnqutsbM+wXOhUZj0PXnwAAhrNrjoiIDMAxTVTAE2UWen1xSpswjWpZFQdntitywpSvha8jdk1qg+rOtnisyMLgb0Jw7GacMULWy29XHmHCxlDkagS6N3BDHXe7Ejs2ERGVfUyaSIdGIzDrlyt4kJgBT7kVtkxsiY8G+KOSnt1xL1LN2RY7JwWiVXVHpKlyMXFjKDaF3DfKvp9nw5l7mB58BTlqgT6NPPHliKbFfkwiIipfmDSRjnWn7uLM7URYW5hh82st8Uqtl2tdKoyDjSU2TWiJwQFVoBHAe79dw+I915Cj1hj9WEIIfHLwbyz5/TqAvPmkPh/WGJbmvPSJiMgw/OQgrfBoBT45eBMAsKhPfdRwqVRsx7I0l+KTwQ3xTo86AICNZ++j75oz+CsqxWjHyFVrMG9HOL46dgcA8L/udbCoT31IpRKjHYOIiCoOJk0EIG/g97Tgy8jVCPT0c8ewEniArUQiwaQONfHNqKZwsLHAjRglBnx9Bu//fh3pqtyX2ndWjhpv/3QJ2y5GQSoBlg/0x+SONSGRMGEiIqKiYdJEAID3f7+Oewnp8JBbYdlA/xJNLnr6e+DwrPbo19gTGgH8cOYeuq06iWN/F22QuCIzB2PXX8Ch609gaS7FN6MDMLwF75QjIqKXw6SJsD88BtsuRkEiAT4b2hgONpYlHoNzJRk+H94EG15tDi8HazxKycSrG0Mx5edLiE9V6b2fJ8osDPsuBBfuJ8HOyhybJ7RA9wbuxRg5ERFVFEyaKrjHKZmYt+MqAODt9jXQukbBR6KUpI51XHFoVju83tYXUgmw92oMOq88jm2hDyHE8x/Bcjc+DQO/Pou/Y1PhYifDL2+2RstCHvFCRERUFEyaKjC1RmDmtitQZuWiURU5ZnatbeqQAAA2lub4v9718dvkV9DA0x7KrFzM3RGO4WvP4W58WqHb/BWVgsHfhuBRSiaqOdlg59uBqOdRshNnEhFR+cakqQL79sQdnL+XBFtLM3w+vAkszErX5eBfRY7fJrfBgl51YWUhxfl7Sejx+SmsORqJ7Nx/pyc4FRmPEevOISk9G/5ecmx/OxDejjYmjJyIiMojiXhRn0cFoFQqIZfLoVAoYG9fMVonLj9MxuBvQ6DWCHw6pBEGB1QxdUjPFZWUgQW7wnEqMgEAUMfNDksH+uNRSiZm/5I3aWWbmk74bkwzo03ESUREpVtJf34zaULFS5rSVLno9fkpPEzKQFBDD3w5okmZuBVfCIHfrjzG+3uvIyk9G/khCwEENfTAyqGNIDPnA3iJiCqKkv78Ll39MVQiFv12DQ+TMuDlYI2PBpTs9AIvQyKRoH8TLxyZ1R6DmlaBEHkJ07jWPvhieBMmTEREVKzYj1HB7PnrMXZcioZUAqwe3hhyawtTh2SwyraWWDm0EUa29EZCWja61XcrM4kfERGVXUyaKpCopAz8365wAMCUTrXQvJqjiSN6OQE+ZTt+IiIqW9g9V0HkqjWYue0KUrNy0bSqA6Z1qmnqkIiIiMoUJk0VxFfH7uDig2TYyczx+fAmMC9l0wsQERGVdvzkrADCHiTh8yO3AAAfDvDjHEZERERFwKSpnFNm5WB68BVoBDCgiRf6NfYydUhERERlEgeClxFZOWpcepiMrBw1snM1UOVqoMrRQJWrzvte+1JDlaNBtjpvfWRcKqKTM+HtaI33+zUw9WkQERGVWUyayoD4VBWGrw3Bnfj0Im1vJpXg8+FNYGdV9qYXICIiKi2YNJVyyenZGLP+PO7Ep0NubQEfJxtYmkkhs5BCZm4GmbkUMnMpLM2fev/POst/1rWq7sSH1xIREb0kJk2lmDIrB+M2XMDfsalwtZPhlzdbo5qzranDIiIiqpA4ELyUysjOxYQNobgarYCjrSV+eq0lEyYiIiITYtJUCmXlqPHajxdx8UEy7K3MsXliC9RyszN1WERERBUak6ZSJjtXg7e3hOHsnUTYWprhxwkt0MBTbuqwiIiIKrxSkzQtW7YMEokEM2bM0C4bP348JBKJzqtVq1Y626lUKkydOhXOzs6wtbVF3759ER0dXcLRG0euWoPpwZdx7GY8rCyk+GF8czSpWtnUYRERERFKSdIUGhqKtWvXomHDhgXW9ejRAzExMdrX/v37ddbPmDEDu3btQnBwME6fPo20tDQEBQVBrVaXVPhGodYIzPn1L/wREQtLMynWjmmGltWdTB0WERER/cPkSVNaWhpGjRqFdevWoXLlgq0qMpkM7u7u2pej479PtlcoFFi/fj1WrlyJLl26oEmTJtiyZQvCw8Nx+PDhkjyNlyKEwLu7w7H7ymOYSyX4alRTtKvtYuqwiIiI6CkmT5omT56M3r17o0uXLoWuP378OFxdXVG7dm28/vrriIuL064LCwtDTk4OunXrpl3m6ekJPz8/nD179pnHVKlUUCqVOi9TEUJgye/XsfVCFKQSYNWwxuha381k8RAREVHhTDpPU3BwMC5duoTQ0NBC1/fs2RNDhgyBj48P7t27h4ULF6JTp04ICwuDTCZDbGwsLC0tC7RQubm5ITY29pnHXbZsGZYsWWLUcymqTw7exMaz9wEAKwY3Qp9GnqYNiIiIiAplsqQpKioK06dPx59//gkrK6tCywwbNkz7vZ+fH5o1awYfHx/s27cPAwcOfOa+hRCQSCTPXD9//nzMmjVL+16pVMLb27sIZ/Fy1hyNxNfH7wAAPujvh8EBVUo8BiIiItKPyZKmsLAwxMXFISAgQLtMrVbj5MmTWLNmDVQqFczMzHS28fDwgI+PDyIjIwEA7u7uyM7ORnJysk5rU1xcHAIDA595bJlMBplMVuTY01W5uBOfhnsJ6bC1NIe73Arucis42lhCKn12sva070/dxad/3gIAvNu7Hsa08ilyPERERFT8TJY0de7cGeHh4TrLXn31VdStWxdz584tkDABQGJiIqKiouDh4QEACAgIgIWFBQ4dOoShQ4cCAGJiYhAREYEVK1a8dIzKrBzcjkvD7SdpiIxLRWRcGiKfpOFRSmah5S3NpHCTy+Bhbw03uRU85FZwt8/7mv/epZIMwaFR+HDfDQDArK618Vrb6i8dKxERERUvkyVNdnZ28PPz01lma2sLJycn+Pn5IS0tDYsXL8agQYPg4eGB+/fvY8GCBXB2dsaAAQMAAHK5HBMnTsTs2bPh5OQER0dHzJkzB/7+/s8cWP48v1yMwqN04PY/yVGsMuuZZZ0ryVDd2RaZOWrEKrOQkKZCtlqDqKRMRCUVnlQBgFQCaETe9293qIGpnWoaHCcRERGVvFL7wF4zMzOEh4dj06ZNSElJgYeHBzp27Iht27bBzu7fR4qsWrUK5ubmGDp0KDIzM9G5c2ds3Lix0JaqF3n/9+uQymx0lrnbW6GWWyXUdK2EWq52ed+7VEJlW0udctm5GsSlZiFWkYUYRRaeKPO+5r3PRKwiC09SVVD/kzFNaOOLd7rXee7YKyIiIio9JEIIYeogTE2pVEIul2PEV0fQwMcdtVztUPOfRMneysJox1FrBBLTVMjVCHg6WBttv0RERBVR/ue3QqGAvb19sR+v1LY0mcK3o5sVa6WbSSVwtS/8TkEiIiIq3Uw+uSURERFRWcCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgPTJqIiIiI9MCkiYiIiEgP5qYOoDQQQgAAlEqliSMhIiIifeV/bud/jhc3Jk0AUlNTAQDe3t4mjoSIiIgMlZiYCLlcXuzHkYiSSs9KMY1Gg9q1ayMsLAwSiUTv7ZRKJby9vREVFQV7e3u9t2vevDlCQ0MNjrMsbMc60VXU+ijKscrKduW9Tkry96aoxyvp7cpznZSFv69FPV5RtyvJYykUClStWhXJyclwcHAw+JiGYksTAKlUCktLyyJnqfb29gZdwGZmZgZf8GVpO4B18l+G1sfLHKusbFde66Qkf29e5nisE+NsVxb+vr7M8cpKnUilJTNEmwPB/zF58uRSf6yysl1JHqusbFeSxyor25XksUpyu5Ksj5c5HuvEONuVhd+blzleea6TomD33EtQKpWQy+VQKBRFzo7LG9aJLtZHQayTglgnBbFOCmKdFFTSdcKWppcgk8mwaNEiyGQyU4dSarBOdLE+CmKdFMQ6KYh1UhDrpKCSrhO2NBERERHpgS1NRERERHpg0kRERESkByZNRERERHpg0kRERESkhwqdNJ08eRJ9+vSBp6cnJBIJdu/erbP+yZMnGD9+PDw9PWFjY4MePXogMjJSp0xsbCzGjBkDd3d32NraomnTpti+fbtOmeTkZIwZMwZyuRxyuRxjxoxBSkpKMZ9d0ZRUnVSrVg0SiUTnNW/evOI+vSIxRp3cuXMHAwYMgIuLC+zt7TF06FA8efJEp0xFu070qZOycp0sW7YMzZs3h52dHVxdXdG/f3/cvHlTp4wQAosXL4anpyesra3RoUMHXLt2TaeMSqXC1KlT4ezsDFtbW/Tt2xfR0dE6ZcrKdVKSdVLRrpO1a9eiQ4cOsLe3h0QiKfTnX9GuE33qxBjXSYVOmtLT09GoUSOsWbOmwDohBPr374+7d+/it99+w+XLl+Hj44MuXbogPT1dW27MmDG4efMm9uzZg/DwcAwcOBDDhg3D5cuXtWVGjhyJK1eu4MCBAzhw4ACuXLmCMWPGlMg5Gqqk6gQA3n//fcTExGhf7777brGfX1G8bJ2kp6ejW7dukEgkOHr0KM6cOYPs7Gz06dMHGo1Gu6+KdJ3oWydA2bhOTpw4gcmTJ+PcuXM4dOgQcnNz0a1bN53fixUrVuCzzz7DmjVrEBoaCnd3d3Tt2lX77EsAmDFjBnbt2oXg4GCcPn0aaWlpCAoKglqt1pYpK9dJSdYJULGuk4yMDPTo0QMLFix45rEq2nWiT50ARrhOBAkhhAAgdu3apX1/8+ZNAUBERERol+Xm5gpHR0exbt067TJbW1uxadMmnX05OjqK77//XgghxPXr1wUAce7cOe36kJAQAUD8/fffxXQ2xlFcdSKEED4+PmLVqlXFFntxKUqdHDx4UEilUqFQKLRlkpKSBABx6NAhIUTFu070qRMhyu51EhcXJwCIEydOCCGE0Gg0wt3dXSxfvlxbJisrS8jlcvHtt98KIYRISUkRFhYWIjg4WFvm0aNHQiqVigMHDgghyvZ1Ulx1IkTFuk6eduzYMQFAJCcn6yyvaNfJ055VJ0IY5zqp0C1Nz6NSqQAAVlZW2mVmZmawtLTE6dOntcteeeUVbNu2DUlJSdBoNAgODoZKpUKHDh0AACEhIZDL5WjZsqV2m1atWkEul+Ps2bMlczJGYqw6yffxxx/DyckJjRs3xkcffYTs7OwSOQ9j0qdOVCoVJBKJzuRrVlZWkEql2jIV7TrRp07ylcXrRKFQAAAcHR0BAPfu3UNsbCy6deumLSOTydC+fXvtzzcsLAw5OTk6ZTw9PeHn56ctU5avk+Kqk3wV5TrRR0W7TgzxstcJk6ZnqFu3Lnx8fDB//nwkJycjOzsby5cvR2xsLGJiYrTltm3bhtzcXDg5OUEmk+HNN9/Erl27UKNGDQB543tcXV0L7N/V1RWxsbEldj7GYKw6AYDp06cjODgYx44dw5QpU7B69WpMmjTJFKf1UvSpk1atWsHW1hZz585FRkYG0tPT8b///Q8ajUZbpqJdJ/rUCVA2rxMhBGbNmoVXXnkFfn5+AKD9Gbq5uemUdXNz066LjY2FpaUlKleu/NwyZfE6Kc46ASrWdaKPinad6MsY14m5QaUrEAsLC+zYsQMTJ06Eo6MjzMzM0KVLF/Ts2VOn3Lvvvovk5GQcPnwYzs7O2L17N4YMGYJTp07B398fACCRSArsXwhR6PLSzJh1MnPmTG35hg0bonLlyhg8eLD2v4CyQp86cXFxwa+//oq3334bX3zxBaRSKUaMGIGmTZvCzMxMW64iXSf61klZvE6mTJmCq1evFmgxAwr+jPX5+f63TFm8Toq7TnidFMTrpCBjXCdMmp4jICAAV65cgUKhQHZ2NlxcXNCyZUs0a9YMQN7dP2vWrEFERAQaNGgAAGjUqBFOnTqFr776Ct9++y3c3d0L3BEEAPHx8QUy57LAGHVSmFatWgEAbt++XWr/yD3Li+oEALp164Y7d+4gISEB5ubmcHBwgLu7O3x9fQGgwl0nwIvrpDCl/TqZOnUq9uzZg5MnT6JKlSra5e7u7gDy/mv28PDQLo+Li9P+fN3d3ZGdnY3k5GSdlpW4uDgEBgZqy5S166S466Qw5fk60UdFu06KqijXCbvn9CCXy+Hi4oLIyEhcvHgR/fr1A5A3Wh8ApFLdajQzM9PeAdS6dWsoFApcuHBBu/78+fNQKBTP/aUv7V6mTgqTf2fd078UZc2z6uRpzs7OcHBwwNGjRxEXF4e+ffsCqHjXydOeVSeFKa3XiRACU6ZMwc6dO3H06NECiZ+vry/c3d1x6NAh7bLs7GycOHFC+/MNCAiAhYWFTpmYmBhERERoy5Sl66Sk6qQw5fk60UdFu06KqkjXyUsNIy/jUlNTxeXLl8Xly5cFAPHZZ5+Jy5cviwcPHgghhPjll1/EsWPHxJ07d8Tu3buFj4+PGDhwoHb77OxsUbNmTdG2bVtx/vx5cfv2bfHpp58KiUQi9u3bpy3Xo0cP0bBhQxESEiJCQkKEv7+/CAoKKvHz1UdJ1MnZs2e1+717967Ytm2b8PT0FH379jXJOb/Iy9aJEEL88MMPIiQkRNy+fVts3rxZODo6ilmzZumUqUjXiRAvrpOydJ28/fbbQi6Xi+PHj4uYmBjtKyMjQ1tm+fLlQi6Xi507d4rw8HAxYsQI4eHhIZRKpbbMW2+9JapUqSIOHz4sLl26JDp16iQaNWokcnNztWXKynVSUnVSEa+TmJgYcfnyZbFu3ToBQJw8eVJcvnxZJCYmastUtOvkRXVirOukQidN+bcm/vc1btw4IYQQn3/+uahSpYqwsLAQVatWFe+++65QqVQ6+7h165YYOHCgcHV1FTY2NqJhw4YFbrdPTEwUo0aNEnZ2dsLOzk6MGjWq0NshS4OSqJOwsDDRsmVLIZfLhZWVlahTp45YtGiRSE9PL8lT1Zsx6mTu3LnCzc1NWFhYiFq1aomVK1cKjUajU6aiXScvqpOydJ0UVhcAxIYNG7RlNBqNWLRokXB3dxcymUy0a9dOhIeH6+wnMzNTTJkyRTg6Ogpra2sRFBQkHj58qFOmrFwnJVUnFfE6WbRo0Qv3U9GukxfVibGuE8k/QRMRERHRc3BMExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExEREZEemDQRERER6YFJExGVCUIIdOnSBd27dy+w7uuvv4ZcLsfDhw9NEBkRVRRMmoioTJBIJNiwYQPOnz+P7777Trv83r17mDt3Lj7//HNUrVrVqMfMyckx6v6IqGxj0kREZYa3tzc+//xzzJkzB/fu3YMQAhMnTkTnzp3RokUL9OrVC5UqVYKbmxvGjBmDhIQE7bYHDhzAK6+8AgcHBzg5OSEoKAh37tzRrr9//z4kEgl++eUXdOjQAVZWVtiyZYspTpOISik+e46Iypz+/fsjJSUFgwYNwgcffIDQ0FA0a9YMr7/+OsaOHYvMzEzMnTsXubm5OHr0KABgx44dkEgk8Pf3R3p6Ot577z3cv38fV65cgVQqxf379+Hr64tq1aph5cqVaNKkCWQyGTw9PU18tkRUWjBpIqIyJy4uDn5+fkhMTMT27dtx+fJlnD9/HgcPHtSWiY6Ohre3N27evInatWsX2Ed8fDxcXV0RHh4OPz8/bdK0evVqTJ8+vSRPh4jKCHbPEVGZ4+rqijfeeAP16tXDgAEDEBYWhmPHjqFSpUraV926dQFA2wV3584djBw5EtWrV4e9vT18fX0BoMDg8WbNmpXsyRBRmWFu6gCIiIrC3Nwc5uZ5f8I0Gg369OmDjz/+uEA5Dw8PAECfPn3g7e2NdevWwdPTExqNBn5+fsjOztYpb2trW/zBE1GZxKSJiMq8pk2bYseOHahWrZo2kXpaYmIibty4ge+++w5t27YFAJw+fbqkwySiMo7dc0RU5k2ePBlJSUkYMWIELly4gLt37+LPP//EhAkToFarUblyZTg5OWHt2rW4ffs2jh49ilmzZpk6bCIqY5g0EVGZ5+npiTNnzkCtVqN79+7w8/PD9OnTIZfLIZVKIZVKERwcjLCwMPj5+WHmzJn45JNPTB02EZUxvHuOiIiISA9saSIiIiLSA5MmIiIiIj0waSIiIiLSA5MmIiIiIj0waSIiIiLSA5MmIiIiIj0waSIiIiLSA5MmIiIiIj0waSIiIiLSA5MmIiIiIj0waSIiIiLSA5MmIiIiIj38P1rrvxhv17i/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_targets.groupby(\"Year\")['y_raw'].mean().plot(ylabel=\"Average popularity of all topics\",title=\"Increasing popularity over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6aa3ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3 0.918\n",
      "-2 0.946\n",
      "-1 0.973\n",
      "0 1.0\n",
      "1 0.991\n",
      "2 0.981\n",
      "3 0.97\n",
      "4 0.959\n",
      "5 0.946\n",
      "6 0.933\n",
      "7 0.919\n",
      "8 0.906\n"
     ]
    }
   ],
   "source": [
    "# # df_targets.groupby('variable')['y_raw'].apply(lambda x: x.autocorr(lag=1)).mean().round(3)\n",
    "# df_g = df_targets.groupby([\"variable\"])\n",
    "# for i in range(-2,7):#[-1,0,1,2]:\n",
    "#     print(i,df_g.apply(lambda df2: df2['y_raw'].corr(df2['y_raw'].shift(i))).mean().round(3))\n",
    "\n",
    "# df_targets.groupby(\"variable\")[\"y_raw\"].shift(-5)\n",
    "for i in range(-3,9):\n",
    "    ## assumes data sorted! \n",
    "    df_targets[\"lagged\"] = df_targets.groupby(\"variable\")[\"y_raw\"].shift(i).fillna(0) ## fillna 0 greatly changes results!!\n",
    "    print(i,df_targets['y_raw'].corr(df_targets[\"lagged\"]).round(3))\n",
    "    df_targets.drop(columns=[\"lagged\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb812b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.plotting.autocorrelation_plot(df_targets.groupby('variable')['y_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce57524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        103.5087\n",
       "1          2.1269\n",
       "2         13.8248\n",
       "3          4.2538\n",
       "4          1.0634\n",
       "          ...    \n",
       "4170    1467.2528\n",
       "4171     588.2531\n",
       "4172     188.3969\n",
       "4173     393.6532\n",
       "4174     238.4186\n",
       "Name: y_raw, Length: 4175, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets[\"y_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e5b4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Correlation with target (y_raw) at same time (not lagged):\")\n",
    "# df_targets.corrwith(df_targets[\"y_raw\"]).round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a36f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Lagged with target as it will be in 3 years:\")\n",
    "# df_targets.corrwith(df_targets.groupby(\"variable\")[\"y_raw\"].shift(-3),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef398f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged with target as it will be in 5 years:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'corr' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLagged with target as it will be in 5 years:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrwith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvariable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspearman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msort_values()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:10301\u001b[0m, in \u001b[0;36mDataFrame.corrwith\u001b[0;34m(self, other, axis, drop, method, numeric_only)\u001b[0m\n\u001b[1;32m  10298\u001b[0m this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_numeric_data() \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m  10300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series):\n\u001b[0;32m> 10301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n\u001b[1;32m  10304\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_get_numeric_data()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:10301\u001b[0m, in \u001b[0;36mDataFrame.corrwith.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10298\u001b[0m this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_numeric_data() \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m  10300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series):\n\u001b[0;32m> 10301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m  10303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n\u001b[1;32m  10304\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_get_numeric_data()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:2727\u001b[0m, in \u001b[0;36mSeries.corr\u001b[0;34m(self, other, method, min_periods)\u001b[0m\n\u001b[1;32m   2724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m   2726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkendall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(method):\n\u001b[0;32m-> 2727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnancorr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_periods\u001b[49m\n\u001b[1;32m   2729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2732\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2733\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkendall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or a callable, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2734\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2735\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/nanops.py:91\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m obj_iter):\n\u001b[1;32m     90\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduction operation \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not allowed for this dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: reduction operation 'corr' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "print(\"Lagged with target as it will be in 5 years:\")\n",
    "df_targets.corrwith(df_targets.groupby(\"variable\")[\"y_raw\"].shift(-5),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d197f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(reverse) Lagged with target as it was 5 years ago\")\n",
    "df_targets.corrwith(df_targets.groupby(\"variable\")[\"y_raw\"].shift(5),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dfd8c0",
   "metadata": {},
   "source": [
    "##### Corr with lagged, diffed target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation with target diff_lag5 at same time (not lagged):\")\n",
    "df_targets.corrwith(df_targets[\"diff_lag5\"],method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lagged with target diff_lag5 as it will be in 5 years:\")\n",
    "df_targets.corrwith(df_targets.groupby(\"variable\")[\"diff_lag5\"].shift(-5),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba024ee4",
   "metadata": {},
   "source": [
    "`pct_diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bfe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lagged with target lag5_pct_new, unlagged\")\n",
    "df_targets.corrwith(df_targets[\"lag5_pct_new\"],method=\"spearman\").round(3).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8aff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lagged with target pct_diff (vs 5 y ago) as it will be in 5 years:\")\n",
    "df_targets.corrwith(df_targets.groupby(\"variable\")[\"lag5_pct_new\"].shift(-5),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9385863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.corrwith(df_targets[\"diff_lag5\"].shift(-5),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed076a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_targets.corrwith(df_targets.groupby(\"variable\")[\"diff_lag5\"].shift(-5),method=\"spearman\").round(2).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba1936",
   "metadata": {},
   "source": [
    "### Baseline model - lag raw\n",
    "* baseline model of input features, lag 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89eb08f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>variable</th>\n",
       "      <th>y_raw</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>BLAST</td>\n",
       "      <td>103.5087</td>\n",
       "      <td>109.7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Brodmann area</td>\n",
       "      <td>2.1269</td>\n",
       "      <td>2.7169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Cingulate cortex</td>\n",
       "      <td>13.8248</td>\n",
       "      <td>8.9747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>DNA array</td>\n",
       "      <td>4.2538</td>\n",
       "      <td>12.3464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>Dorsolateral prefrontal cortex</td>\n",
       "      <td>1.0634</td>\n",
       "      <td>2.4026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>1467.2528</td>\n",
       "      <td>139.7049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>viral therapy</td>\n",
       "      <td>588.2531</td>\n",
       "      <td>649.8641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>vitamin C</td>\n",
       "      <td>188.3969</td>\n",
       "      <td>-24.9629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>vitamin D</td>\n",
       "      <td>393.6532</td>\n",
       "      <td>13.1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>zebra fish</td>\n",
       "      <td>238.4186</td>\n",
       "      <td>70.4693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4175 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year                        variable      y_raw  target_5\n",
       "0    1979-01-01                           BLAST   103.5087  109.7888\n",
       "1    1979-01-01                   Brodmann area     2.1269    2.7169\n",
       "2    1979-01-01                Cingulate cortex    13.8248    8.9747\n",
       "3    1979-01-01                       DNA array     4.2538   12.3464\n",
       "4    1979-01-01  Dorsolateral prefrontal cortex     1.0634    2.4026\n",
       "...         ...                             ...        ...       ...\n",
       "4170 2015-01-01                         vaccine  1467.2528  139.7049\n",
       "4171 2015-01-01                   viral therapy   588.2531  649.8641\n",
       "4172 2015-01-01                       vitamin C   188.3969  -24.9629\n",
       "4173 2015-01-01                       vitamin D   393.6532   13.1577\n",
       "4174 2015-01-01                      zebra fish   238.4186   70.4693\n",
       "\n",
       "[4175 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_targets[\"target_5\"] = df_targets.groupby(\"variable\")[\"y_raw\"].shift(-2)\n",
    "df_targets[[\"Year\",\"variable\",\"y_raw\",\"target_5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c6aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lagged = df_targets.dropna(subset=[\"target_5\"],axis=0).copy()\n",
    "\n",
    "df_lagged = df_targets.filter(['variable', 'reviews',\n",
    "                              'patent_count', 'patent_frac','patent_yearly_total',\n",
    "                               'year_num', \n",
    "\"y_raw\",                              ## ADdded: Here it is 5 befre?  NEW\n",
    "                              \"lag5_pct_new\",\"pct_diff_lag5\", ## also new - check not leak? \n",
    "                              'research_review_diff',\n",
    "       'research_review_ratio', 'pct_diff', \n",
    "                              'review_research_ratio_2',\n",
    "       'review_research_diff_2', 'pat_div_research',\n",
    "        'y_diff','y_pct_diff', \n",
    "        'target_5']).reset_index(drop=True)\n",
    "\n",
    "num_cols = list(df_lagged.select_dtypes(\"number\").drop(columns=['target_5',\n",
    "#                                                                 \"y_raw\", ### Keeep? NEW\n",
    "                                                                \"y_raw_predicted\",\"preds\"],errors=\"ignore\").columns)\n",
    "df_lagged = df_lagged.filter([\"variable\",\"target_5\"]+num_cols,axis=1)\n",
    "mask = ~df_lagged[\"target_5\"].isna()\n",
    "# X = df_lagged[[\"variable\"]+num_cols]#.copy() \n",
    "# y = df_lagged[\"target_5\"] ## target in 5Y\n",
    "\n",
    "X = df_lagged[mask][[\"variable\"]+num_cols]#.copy() \n",
    "y = df_lagged[mask][\"target_5\"] ## target in 5Y\n",
    "assert (X.shape[0]>100)\n",
    "assert (y.isna().sum()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082fba13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre embed non linear model (with all numeric features)\n",
      "4\n",
      "8\n",
      "12\n",
      "16\n",
      "20\n",
      "24\n",
      "28\n",
      "r2: 0.817\n",
      "MAE (Mean absolute error): 75.736\n",
      "Median absolute error: 28.527\n",
      "RMSE: 167.126\n",
      "explained_variance:  0.817\n",
      "mape: 6.134\n",
      "CPU times: user 46 s, sys: 8.7 s, total: 54.7 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if GET_DL_EMBEDS:\n",
    "    print(\"Pre embed non linear model (with all numeric features)\")\n",
    "    i = 0\n",
    "    tscv = TimeSeriesSplit(NUM_CV_FOLDS)\n",
    "    df_lagged[\"preds\"] = np.NaN\n",
    "    X2 = X.select_dtypes(\"number\")\n",
    "    for train_index, test_index in tscv.split(X): #df_feat):\n",
    "        i +=1\n",
    "        if (i%4)==0: print(i)\n",
    "        X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = CatBoostRegressor(iterations=300,\n",
    "    #                               cat_features= [\"variable\"],\n",
    "                          verbose=False,has_time=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        assert np.isnan(y_predict).max() == False\n",
    "    #         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "        df_lagged.iloc[test_index,-1] =y_predict\n",
    "\n",
    "    y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "    y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "    regression_results(y_true_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f02b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 12:18:22.086623: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-21 12:18:22.107019: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 12:18:22.508407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6a7bbee9274660bee9295939d2cfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 384)\n",
      "[0.07219416 0.04845907]\n",
      "0.8861598717048764\n",
      "64\n",
      "(4175, 17)\n",
      "(4175, 81)\n"
     ]
    }
   ],
   "source": [
    "## frequently crashes when running on cpu, randomly. # but -  it improves model perf!! \n",
    "if GET_DL_EMBEDS:\n",
    "    import gc\n",
    "    import torch\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    torch.cuda.empty_cache()\n",
    "    model = SentenceTransformer('all-MiniLM-L12-v2',device=\"cpu\") # same res with L6\n",
    "    #Our sentences we like to encode\n",
    "    sentences = list(df_lagged[\"variable\"].unique())\n",
    "    print(len(sentences))\n",
    "\n",
    "    #Sentences are encoded by calling model.encode()\n",
    "    embeddings = model.encode(sentences,batch_size=128,show_progress_bar=True,)#.to(\"cpu\")\n",
    "\n",
    "    df_embed_feats = pd.DataFrame(index=sentences, data=embeddings)\n",
    "    print(df_embed_feats.shape)\n",
    "    df_embed_feats.columns = [\"embed_\"+str(i) for i in df_embed_feats.columns]\n",
    "    df_embed_feats.to_parquet(\"var_text_embeddings.parquet\")\n",
    "    \n",
    "#     ### OPT - truncate size of dims\n",
    "#     ### Has SAME Results as using all embeds\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(64)#64)\n",
    "    pca.fit(df_embed_feats)\n",
    "    print(pca.explained_variance_ratio_[0:2])\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    print(len(pca.singular_values_))\n",
    "    df_embed_feats = pd.DataFrame(pca.transform(df_embed_feats),index=df_embed_feats.index)\n",
    "    df_embed_feats.columns = [\"embed_\"+str(i) for i in df_embed_feats.columns]\n",
    "\n",
    "    print(X.shape)\n",
    "    X = X.join(df_embed_feats,on=\"variable\",how=\"left\")\n",
    "    df_lagged = df_lagged.join(df_embed_feats,on=\"variable\",how=\"left\")\n",
    "    ### our prediction code assumes \"pred\" to be the last column - resort this - hack\n",
    "    temp = df_lagged[\"preds\"]\n",
    "    df_lagged.drop(columns=[\"preds\"],inplace=True)\n",
    "    df_lagged[\"preds\"] = temp\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03c21a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive lag model\n",
      "Baseline Lag model\n",
      "r2: 0.196\n",
      "MAE (Mean absolute error): 180.445\n",
      "Median absolute error: 65.341\n",
      "RMSE: 350.34\n",
      "explained_variance:  0.198\n",
      "mape: 12.831\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive lag model\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "tscv = TimeSeriesSplit(NUM_CV_FOLDS)#10)\n",
    "df_lagged[\"preds\"] = np.NaN\n",
    "X2 = X[[\"y_raw\"]].copy()\n",
    "for train_index, test_index in tscv.split(X2): #df_feat):\n",
    "    i +=1\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RidgeCV()#LinearRegression() ## better results\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "#         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "    df_lagged.iloc[test_index,-1] =y_predict\n",
    "    \n",
    "print(\"Baseline Lag model\")\n",
    "y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "assert y_pred_base.shape[0]>4\n",
    "regression_results(y_true_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93eb2353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model\n",
      "r2: 0.554\n",
      "MAE (Mean absolute error): 149.916\n",
      "Median absolute error: 88.486\n",
      "RMSE: 261.09\n",
      "explained_variance:  0.554\n",
      "mape: 29.342\n",
      "CPU times: user 1.38 s, sys: 3.31 s, total: 4.69 s\n",
      "Wall time: 303 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ## TMP copy of df, since function expects to put results in df_feat, which doesn't exist yet\n",
    "# df_feat = df_lagged.copy()\n",
    "# # df_feat.drop(columns=[\"preds\"],errors=\"ignore\",inplace=True)\n",
    "# evaluate(model = CatBoostRegressor(verbose=False,has_time=True),X = X[[\"y_raw\"]])\n",
    "\n",
    "# print(\"Baseline Lag model\")\n",
    "# y_true_base = df_feat.dropna(subset=[\"preds\"],axis=0)[\"target_5\"]\n",
    "# y_pred_base = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "# regression_results(y_true_base, y_pred_base)\n",
    "\n",
    "i = 0\n",
    "tscv = TimeSeriesSplit(NUM_CV_FOLDS)#10)\n",
    "df_lagged[\"preds\"] = np.NaN\n",
    "X2 = X.select_dtypes([\"number\"]).fillna(X.select_dtypes([\"number\"]).mean()).copy()\n",
    "for train_index, test_index in tscv.split(X2): #df_feat):\n",
    "    i +=1\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RidgeCV()#LinearRegression() ## better results\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "#         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "    df_lagged.iloc[test_index,-1] =y_predict\n",
    "    \n",
    "print(\"Linear model\")\n",
    "y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "assert y_pred_base.shape[0]>4\n",
    "regression_results(y_true_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2aa81821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model with all features\n",
      "r2: 0.539\n",
      "MAE (Mean absolute error): 152.423\n",
      "Median absolute error: 90.412\n",
      "RMSE: 265.419\n",
      "explained_variance:  0.539\n",
      "mape: 29.061\n",
      "CPU times: user 1.25 s, sys: 3.92 s, total: 5.17 s\n",
      "Wall time: 323 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"linear model with all features\")\n",
    "i = 0\n",
    "tscv = TimeSeriesSplit(NUM_CV_FOLDS)#10)\n",
    "df_lagged[\"preds\"] = np.NaN\n",
    "X2 = X.select_dtypes(\"number\").dropna(how=\"any\",axis=1)\n",
    "for train_index, test_index in tscv.split(X): \n",
    "    i +=1\n",
    "    X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "#     model = LinearRegression()\n",
    "    model = RidgeCV()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    assert np.isnan(y_predict).max() == False\n",
    "#         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "    df_lagged.iloc[test_index,-1] =y_predict\n",
    "\n",
    "y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "regression_results(y_true_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdb0e0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 ms, sys: 463 µs, total: 1.79 ms\n",
      "Wall time: 140 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not GET_DL_EMBEDS:\n",
    "    print(\"non linear model (with all features)\")\n",
    "    i = 0\n",
    "    tscv = TimeSeriesSplit(NUM_CV_FOLDS)\n",
    "    df_lagged[\"preds\"] = np.NaN\n",
    "    X2 = X.copy()\n",
    "    # X2 = X.select_dtypes(\"number\").copy()\n",
    "    for train_index, test_index in tscv.split(X2): #df_feat):\n",
    "        i +=1\n",
    "        if (i%3)==0: print(i)\n",
    "        X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = CatBoostRegressor(#iterations=300,\n",
    "                                  cat_features= [\"variable\"],\n",
    "                          verbose=False,has_time=True)\n",
    "        model.fit(X_train, y_train,\n",
    "                  )\n",
    "        y_predict = model.predict(X_test)\n",
    "        assert np.isnan(y_predict).max() == False\n",
    "    #         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "        df_lagged.iloc[test_index,-1] =y_predict\n",
    "\n",
    "    y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "    y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "    regression_results(y_true_base, y_pred_base)\n",
    "\n",
    "# ## pct change, with categorical, AND with DL, 30 folds: \n",
    "# r2: 0.438\n",
    "# MAE (Mean absolute error): 47.867\n",
    "# Median absolute error: 14.904\n",
    "# RMSE: 217.729\n",
    "# explained_variance:  0.438\n",
    "# mape: 1.796\n",
    "\n",
    "## this model does better when not using DL embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "259fbae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non linear model (with numeric features)\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n",
      "r2: 0.889\n",
      "MAE (Mean absolute error): 56.613\n",
      "Median absolute error: 20.913\n",
      "RMSE: 130.474\n",
      "explained_variance:  0.889\n",
      "mape: 4.399\n",
      "CPU times: user 5min 47s, sys: 28.8 s, total: 6min 16s\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if GET_DL_EMBEDS:\n",
    "    print(\"non linear model (with numeric features)\")\n",
    "    i = 0\n",
    "    tscv = TimeSeriesSplit(NUM_CV_FOLDS)\n",
    "    df_lagged[\"preds\"] = np.NaN\n",
    "    X2 = X.select_dtypes(\"number\").copy()\n",
    "    for train_index, test_index in tscv.split(X2): #df_feat):\n",
    "        i +=1\n",
    "        if (i%3)==0: print(i)\n",
    "        X_train, X_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = CatBoostRegressor(verbose=False,has_time=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        assert np.isnan(y_predict).max() == False\n",
    "    #         df_feat.loc[test_index,\"preds\"] =y_predict\n",
    "        df_lagged.iloc[test_index,-1] =y_predict\n",
    "\n",
    "    y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "    y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "    regression_results(y_true_base, y_pred_base)\n",
    "\n",
    "\n",
    "# # pct change, without categorical, with DL, 30 folds: \n",
    "# r2: 0.447\n",
    "# MAE (Mean absolute error): 48.291\n",
    "# Median absolute error: 15.114\n",
    "# RMSE: 216.043\n",
    "# explained_variance:  0.447\n",
    "# mape: 1.721"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a2080",
   "metadata": {},
   "source": [
    "## Binary classification results\n",
    "*  `>=` vs decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5cb50da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31417910447761194\n",
      "0.31965174129353235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.91      0.91      2757\n",
      "        True       0.81      0.82      0.81      1263\n",
      "\n",
      "    accuracy                           0.88      4020\n",
      "   macro avg       0.86      0.87      0.86      4020\n",
      "weighted avg       0.88      0.88      0.88      4020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# y_true_base, y_pred_base\n",
    "y_binary_true = y_true_base<0\n",
    "print(y_binary_true.mean())\n",
    "\n",
    "y_binary_pred = y_pred_base<0\n",
    "print(y_binary_pred.mean())\n",
    "\n",
    "print(classification_report(y_true=y_binary_true,y_pred=y_binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46cc00e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.93      0.87        54\n",
      "        True       0.94      0.84      0.89        69\n",
      "\n",
      "    accuracy                           0.88       123\n",
      "   macro avg       0.88      0.88      0.88       123\n",
      "weighted avg       0.88      0.88      0.88       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_date_mask = X[\"year_num\"]==X[\"year_num\"].max()\n",
    "\n",
    "print(classification_report(y_true=y_binary_true[max_date_mask],y_pred=y_binary_pred[max_date_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07a91d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(X.select_dtypes(\"number\").columns[-64:])\n",
    "# [X.columns.get_loc(c) for c in X.columns if ((c in X) and \"embed\" in c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719d49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # list(df_embed_feats[[c for c in X.columns if \"embed\" in c]].values)\n",
    "# X[\"embed\"] = list(X[[c for c in X.columns if \"embed\" in c]].values) # has error wit hembed feat\n",
    "\n",
    "# X[\"embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676128e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U tensorflow==2.10  ## needed to avoid compat error .. ? \n",
    "import shap\n",
    "\n",
    "# X2 = X.select_dtypes(\"number\").copy()\n",
    "X2 = X.copy()\n",
    "model = CatBoostRegressor(#iterations=500,\n",
    "                          cat_features= [\"variable\",\"embed\"],\n",
    "                      verbose=False,has_time=True,\n",
    "#      embedding_features=[\"embed\"],\n",
    "#                       embedding_features=[X2.columns.get_loc(c) for c in X2.columns if ((c in X2) and \"embed\" in c)]\n",
    "                            )\n",
    "model.fit(X2,y)\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X2)\n",
    "\n",
    "# summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values,max_display=15,)\n",
    "# shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fillna Baseline Lag model\")\n",
    "y_true_base = df_lagged[\"target_5\"].fillna(0)\n",
    "y_pred_base = df_lagged[\"y_raw\"].fillna(0)\n",
    "\n",
    "regression_results(y_true_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d78ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Single feature model (vs +5Y)\")\n",
    "### new\n",
    "y_true_base = df_lagged.dropna(subset=[\"preds\"])[\"target_5\"]\n",
    "y_pred_base = df_lagged.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "\n",
    "regression_results(y_true_base, y_pred_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995be6b",
   "metadata": {},
   "source": [
    "* Baseline lag model with just raw variables (res, pat, reviews + year, variable):\n",
    "```\n",
    "Baseline Lag model\n",
    "r2:  0.787\n",
    "MAE (Mean absolute error): 302.0646\n",
    "Median absolute error): 171.7013\n",
    "RMSE:  546.6826\n",
    "explained_variance:  0.7893\n",
    "mean_squared_log_error:  2.3782\n",
    "```\n",
    "\n",
    "\n",
    "* Baseline lag model with ~all variables (including engineered) gets results closer to SB bt still inferior:\n",
    "```\n",
    "Baseline+ engineered Lag model\n",
    "r2:  0.913\n",
    "MAE (Mean absolute error): 162.549\n",
    "Median absolute error): 71.4473\n",
    "RMSE:  350.1588\n",
    "explained_variance:  0.9132\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bfc5e",
   "metadata": {},
   "source": [
    "SB model (copied from below):\n",
    "```\n",
    "r2:  0.965\n",
    "MAE (Mean absolute error): 102.1891\n",
    "Median absolute error): 32.6761\n",
    "RMSE:  254.8408\n",
    "explained_variance:  0.9652\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68c179",
   "metadata": {},
   "source": [
    "### Get future predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c558a",
   "metadata": {},
   "source": [
    "###### ful data for future predictions\n",
    "* Note, there's some \"bad rows\" from early dates - likely due to wrong annotations. Could drop from full data, ignore for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec186ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_targets = df_targets_orig_full.filter(df_lagged.columns,axis=1)\n",
    "\n",
    "if GET_DL_EMBEDS:\n",
    "    df_future_targets = df_future_targets.join(df_embed_feats,on=\"variable\",how=\"left\")\n",
    "\n",
    "df_future_targets = df_future_targets.loc[df_future_targets[\"target_5\"].isna()]\n",
    "display(df_future_targets)\n",
    "df_future_targets = df_future_targets.loc[df_future_targets[\"year_num\"]>2012].drop(columns=[\"target_5\"],errors=\"ignore\").drop_duplicates()\n",
    "print(df_future_targets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_targets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[X[\"year_num\"]>2005]  # ~1200 rows\n",
    "y.tail(1000).describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2592366",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_COLS_LST =['variable', 'pred', 'y_raw',\"pred_year\", 'year_num',\n",
    "                'reviews', 'patent_count',\n",
    "       'pct_diff_lag5', 'y_diff', 'y_pct_diff']\n",
    "model = CatBoostRegressor(#iterations=700,\n",
    "                          cat_features= [\"variable\"],\n",
    "                      verbose=False,has_time=True)\n",
    "model.fit(X, y)#,baseline=X_train[\"y_raw\"]\n",
    "df_future_targets[\"pred_year\"] = df_future_targets[\"year_num\"]+5\n",
    "df_future_targets = df_future_targets.loc[df_future_targets[\"pred_year\"]>=2019].reset_index(drop=True)\n",
    "df_future_targets[\"pred\"] = model.predict(df_future_targets.drop(columns=[\"pred\",\"pred_year\"],errors=\"ignore\")).round(2)\n",
    "df_future_targets.sort_values([\"pred\",\"variable\"],inplace=True)\n",
    "\n",
    "df_res = df_future_targets.loc[df_future_targets[\"pred_year\"].between(2022,2022)][VIEW_COLS_LST].round(2)\n",
    "# display(df_future_targets[VIEW_COLS_LST].round(2).drop_duplicates(subset=[\"variable\"],keep=\"first\").head(10))\n",
    "# display(df_future_targets[VIEW_COLS_LST].round(2).tail(15))\n",
    "\n",
    "display(df_res.drop_duplicates(subset=[\"variable\"],keep=\"first\").head(15))\n",
    "display(df_res.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5bc74",
   "metadata": {},
   "source": [
    "* declining (predicted, and actual) pop terms:\n",
    "https://esperr.github.io/pubmed-by-year/?q1=pituitary%20gland&q2=serotonin&q3=eugenics&q4=Medulla%20oblongata&q5=influenza&q6=DNA%20array&q7=junk%20dna&q8=subthalamus&q9=neuropeptide&startyear=2000&endyear=2022\n",
    "\n",
    "\n",
    "* PRedicted to increase terms:\n",
    "\n",
    "`https://esperr.github.io/pubmed-by-year/?q1=Mononucleosis&q2=Drug%20repurposing&q3=machine%20learning&q4=Synthetic%20Biology&q5=NGS&q6=cumin&q7=nanopore&q8=cannabidiol&q9=graph%20neural%20network&q10=metabolome&q11=carbon%20nanotubes&q12=illumina&q13=miRNA&q14=biosimilar&q15=connectome&q16=lncRNA&q17=natural%20medicine&q18=CRISPR&q19=lithium&startyear=2000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.drop_duplicates(subset=[\"variable\"],keep=\"first\").head(15)[\"variable\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Increasing (predicted) popularity:\")\n",
    "display(df_res.drop_duplicates(subset=[\"variable\"],keep=\"last\").tail(20))\n",
    "df_res.drop_duplicates(subset=[\"variable\"],keep=\"last\").tail(20)[\"variable\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5685d7",
   "metadata": {},
   "source": [
    "### (Predicted) Non trivial flips of direction\n",
    "* cases where prediction is in a different direction than 5Y, 1 Y momentum\n",
    "    * Many are ~ 0 change (i.e. nearly stable , but can shift a bit up or down)\n",
    "    \n",
    "https://esperr.github.io/pubmed-by-year/?q1=Norepinephrine&q2=HMM&q3=zebra%20fish&q4=savant&q5=genetic%20algorithm&q6=carbon%20dating&q7=ancient%20viruses&q8=viral%20therapy&q9=amygdala&q10=eugenics&q11=carbon%20nanotubes&q12=cerebellum&q13=hippocampus&q14=MRI&q15=Mononucleosis&q16=neocortex&q17=antibiotic&startyear=2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_trend_mask = (np.sign(df_res[\"pct_diff_lag5\"]) != np.sign(df_res[\"pred\"]))\\\n",
    "          & (np.sign(df_res[\"y_pct_diff\"]) != np.sign(df_res[\"pred\"]))\n",
    "print(df_res.loc[flip_trend_mask][\"variable\"].unique())\n",
    "df_res.loc[(flip_trend_mask) & (df_res['y_pct_diff'].abs().round(2)> 0)][['variable', 'pred', 'y_raw',\"pred_year\", 'y_diff', 'y_pct_diff']]#[\"variable\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ff67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.drop_duplicates(subset=[\"variable\"],keep=\"first\").head(9)[\"variable\"].unique()\n",
    "\n",
    "## actual search res (terms all declined):\n",
    "## https://esperr.github.io/pubmed-by-year/?q1=eugenics&q2=somatosensory%20cortex&q3=junk%20dna&q4=influenza&q5=soy%20milk&q6=paleocortex&q7=ancient%20dna&startyear=1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446aa611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_targets.loc[df_future_targets.reset_index().groupby(['variable'])['pred'].idxmax()].sort_values(\"pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716185d",
   "metadata": {},
   "source": [
    "### Features data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea780e8f",
   "metadata": {},
   "source": [
    "* change to after start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02565020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_feat = pd.read_csv(\"trends_demo_rev22_predicted.tsv.gz\",sep=\"\\t\",parse_dates=[\"Year\",\"first\",\"start\"])\n",
    "\n",
    "df_feat = df_feat.loc[df_feat[\"Year\"]> df_feat[\"start\"]]\n",
    "df_feat = df_feat.loc[(df_feat[\"Year\"]> df_feat[\"start\"]) & (df_feat[\"year_num\"]>= 1979) ].reset_index(drop=True)\n",
    "\n",
    "df_feat.sort_values(\"Year\",inplace=True,ascending=True) ## sort by year , not topic\n",
    "df_feat[\"variable\"] = df_feat[\"variable\"].str.strip('\"')\n",
    "\n",
    "df = df_feat.filter(['Year', 'variable', 'y_raw',\"preds\",'y_raw_predicted',  'first', 'start', 'year_num',\n",
    "               \"pct_diff_lag6\"],axis=1).set_index(\"Year\").copy()\n",
    "\n",
    "df.rename(columns={\"y_raw_predicted\":\"preds\"},inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_DL_EMBEDS:\n",
    "    df_embed_feats = pd.read_parquet(\"var_text_embeddings.parquet\")\n",
    "    print(df_embed_feats.shape)\n",
    "#     df_embed_feats.columns = [\"embed_\"+str(i) for i in df_embed_feats.columns]\n",
    "\n",
    "#     ### OPT - truncate size of dims\n",
    "#     ### Has SAME Results as using all embeds\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(64)\n",
    "    pca.fit(df_embed_feats)\n",
    "    print(pca.explained_variance_ratio_[0:2])\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    print(len(pca.singular_values_))\n",
    "    df_embed_feats = pd.DataFrame(pca.transform(df_embed_feats),index=df_embed_feats.index)\n",
    "    df_embed_feats.columns = [\"embed_\"+str(i) for i in df_embed_feats.columns]\n",
    "\n",
    "    print(df_feat.shape)\n",
    "#     X = X.join(df_embed_feats,on=\"variable\",how=\"left\")\n",
    "#     df_lagged = df_lagged.join(df_embed_feats,on=\"variable\",how=\"left\")\n",
    "    df_feat = df_feat.join(df_embed_feats,on=\"variable\",how=\"left\")\n",
    "    print(df_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df_feat.filter(list(df_feat.select_dtypes([\"number\"]).columns)+[\"variable\"],axis=1)\n",
    "df_feat = df_feat.T.drop_duplicates().T.infer_objects() ## drop some duplicate cols\n",
    "\n",
    "# changed:\n",
    "df_feat[\"variable\"] = df_feat[\"variable\"].astype(\"category\")\n",
    "df_feat.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "### make prettier column names from SB features\n",
    "# truncate long numbers in the column names\n",
    "# df_feat.columns = df_feat.columns.str.replace(r'\\d+\\.\\d{3}\\d*', lambda x: '{:.3f}'.format(float(x.group(0))))\n",
    "df_feat.columns = df_feat.columns.str.replace(r'\\d+\\.\\d{3}\\d*', lambda x: '{:.2f}'.format(float(x.group(0))),regex=True) # changed top .2f res\n",
    "\n",
    "# df_feat.columns = df_feat.columns.str.replace(\"and 5 years before\",\"before\")\n",
    "df_feat.columns = df_feat.columns.str.replace(\"between 11 years and 5 years before\",\"between 11 and 5 years before\")\n",
    "df_feat.columns = df_feat.columns.str.replace(\"between 11 years and 5 years before\",\"between 20 and 5 years before\")\n",
    "df_feat.columns = df_feat.columns.str.replace(\"trends_context_v5.csv.gz_\",\"trends-\")\n",
    "df_feat.columns = df_feat.columns.str.replace(\"Year\",\"date\")\n",
    "df_feat.columns = df_feat.columns.str.replace(\"(?<!^)variable\",\"topic\",regex=True)\n",
    "\n",
    "df_feat.columns = df_feat.columns.str.replace(\"_from_date_\",\"\")\n",
    "df_feat.columns = df_feat.columns.str.replace(\"_with_5_years_offset\",\"\")\n",
    "## drop y_raw_predicted ? \n",
    "\n",
    "display(df_feat.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295576b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby([\"variable\"])[\"y_raw\"].transform(\"pct_change\").reset_index()#.describe()\n",
    "### highlky variable topics : \n",
    "# df.groupby([\"variable\"])[\"pct_diff_lag6\"].std().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"variable\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"variable\"].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab994ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"variable\"].value_counts().sort_values().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025e6f9",
   "metadata": {},
   "source": [
    "##### Check variables with high/low errors\n",
    "* +- those with few cases?\n",
    "* I make a pseudo % error target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"error_pct\"] = 100*(df[\"y_raw\"].sub(df[\"preds\"])).div(df[\"y_raw\"]).round(3).replace([np.inf, -np.inf], np.nan)\n",
    "display(df[\"error_pct\"].describe().round(1)) # .dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe908d",
   "metadata": {},
   "source": [
    "### We see the highest errors in the cases with very short time-frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d10be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"variable\"])[\"error_pct\"].median().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401bd55",
   "metadata": {},
   "source": [
    "### REMOVE variables with too few cases\n",
    "* this will improve modelling results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FILTER_GROUP_SIZES:\n",
    "    print(df_feat.shape[0])\n",
    "    element_group_sizes = df_feat['variable'].groupby(df_feat['variable']).transform('count')\n",
    "    df_feat = df_feat[element_group_sizes>6]\n",
    "    df_feat.reset_index(inplace=True,drop=True) # otherwise, error ?? \n",
    "    print(df_feat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_feat[\"y_raw\"].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c88c4",
   "metadata": {},
   "source": [
    "#### opt: make different, touger differenced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09449c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DIFF_TARGET:\n",
    "#     df_feat[\"y_raw\"] = df_feat[\"y_raw\"].sub(df_feat[\"lag5\"])\n",
    "# #     df_feat[\"y_raw\"] = df_feat[\"y_raw\"].div(df_feat[\"lag5\"]) # alt, pct change target\n",
    "#     df_feat.dropna(subset=[\"y_raw\"],inplace=True,axis=0)\n",
    "#     df_feat.reset_index(inplace=True,drop=True)\n",
    "#     display(df_feat[\"y_raw\"].describe().round(2))\n",
    "\n",
    "if DIFF_TARGET_PCT:\n",
    "    df_feat[\"y_raw\"] = 100*df_feat[\"y_raw\"].sub(df_feat[\"lag5\"]).div(df_feat[\"lag5\"]).round(4) # alt, pct change target\n",
    "    ### note outliers.. \n",
    "elif DIFF_TARGET:\n",
    "    df_feat[\"y_raw\"] = df_feat[\"y_raw\"].sub(df_feat[\"lag5\"])\n",
    "#     df_feat[\"y_raw\"] = df_feat[\"y_raw\"].div(df_feat[\"lag5\"]) # alt, pct change target\n",
    "if DIFF_TARGET_PCT or DIFF_TARGET:\n",
    "    df_feat.dropna(subset=[\"y_raw\"],inplace=True)\n",
    "    df_feat.reset_index(inplace=True,drop=True)\n",
    "    display(df_feat[\"y_raw\"].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d40f5a",
   "metadata": {},
   "source": [
    "### temporal CV\n",
    "\n",
    "* https://stackoverflow.com/questions/41753795/sklearn-timeseriessplit-cross-val-predict-only-works-for-partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = list(df_feat.select_dtypes(\"number\").drop(columns=[\"y_raw\",\"y_raw_predicted\",\"preds\"],errors=\"ignore\").columns)\n",
    "\n",
    "# X = df_feat.filter([\"variable\"]+num_cols,axis=1).copy()\n",
    "\n",
    "X = df_feat[[\"variable\"]+num_cols]#.copy() # try values ? \n",
    "# X = X.fillna(0)\n",
    "y = df_feat[\"y_raw\"]#.copy()#.values\n",
    "\n",
    "# ## https://stackoverflow.com/questions/41753795/sklearn-timeseriessplit-cross-val-predict-only-works-for-partitions\n",
    "# preds = cross_val_predict(clf,X.fillna(0),y,cv=cv.split(df_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9026361",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79f513",
   "metadata": {},
   "source": [
    "#### RFECV FS - check overfitting\n",
    "* We see that the best model uses just the features we had engineered in advance (lags and basic transformations).\n",
    "* since we made those in advance and had such a model, using them is not overly problematic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9771f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if DO_RFE_FS:\n",
    "    sfs = RFECV(ElasticNet(l1_ratio=0.35), min_features_to_select=7,step=0.05,\n",
    "                n_jobs=-1,cv=TimeSeriesSplit())\n",
    "    sfs.fit(X.select_dtypes(\"number\"), y)\n",
    "    print(len(sfs.get_feature_names_out()))\n",
    "    list(sfs.get_feature_names_out())\n",
    "\n",
    "if DO_RFE_FS:\n",
    "    print(len(sfs.get_feature_names_out()))\n",
    "    list(sfs.get_feature_names_out())\n",
    "\n",
    "    # X2 = sfs.transform(X.select_dtypes(\"number\"))\n",
    "    X2 = X.filter(list(set([\"variable\",\"year_num\",\"lag5\"]+list(sfs.get_feature_names_out()))),axis=1).copy()\n",
    "    X2\n",
    "else: \n",
    "    X2 = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ab0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### keep subset feats!\n",
    "print(\"Filter feats\")\n",
    "X = X2\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = TimeSeriesSplit(n_splits=NUM_CV_FOLDS)\n",
    "# clf = Ridge(alpha=0.5) # HistGradientBoostingRegressor\n",
    "# clf =HistGradientBoostingRegressor(categorical_features=categorical_mask)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78727251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "print(\"CB full model\")\n",
    "# tscv = TimeSeriesSplit(NUM_CV_FOLDS)\n",
    "df_feat[\"preds\"] = np.NaN\n",
    "\n",
    "evaluate(X=X)\n",
    "\n",
    "display(df_feat.filter([\"year_num\",\"y_raw\",\"preds\",\"y_raw_predicted\",\"variable\"],axis=1).dropna(axis=0))\n",
    "print(df_feat.filter([\"year_num\",\"y_raw\",\"preds\",\"y_raw_predicted\"],axis=1).corrwith(df_feat[\"y_raw\"]).round(3).sort_values())\n",
    "\n",
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3631df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Linear model\")\n",
    "evaluate(model=RidgeCV(),X=X.select_dtypes(\"number\"))\n",
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### single feature baseline\n",
    "regression_results(y_true, y_pred=df_feat.dropna(subset=[\"preds\"])[\"lag5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33119d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.set_index(\"year_num\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: time series CV has nans in predictions, note this when comparing! (e.g. first row per var)\n",
    "df_feat[df_feat[\"preds\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44acda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2:', round(metrics.r2_score(y_true=y_true, y_pred=df_feat.dropna(subset=[\"preds\"])[\"preds\"]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2:', round(metrics.r2_score(y_true=y_true, y_pred=df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98517c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_feat[\"y_raw\"]\n",
    "y_pred = df_feat[\"preds\"].fillna(method=\"bfill\")\n",
    "\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a573b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "# y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, df_feat.dropna(subset=[\"preds\"])[\"lag5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"CB model + Feats\")\n",
    "# df_feat[\"preds\"] = np.NaN\n",
    "# evaluate(X=X,model=CatBoostRegressor(verbose=False,has_time=True,cat_features=[\"variable\"])) # iterations=500,\n",
    "# y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "# y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "# regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CB model + Feats\")\n",
    "df_feat[\"preds\"] = np.NaN\n",
    "evaluate(X=X.select_dtypes(\"number\"),model=CatBoostRegressor(verbose=False,has_time=True)) # iterations=500,\n",
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, y_pred)\n",
    "\n",
    "# ## all feats, CAtboost model:\n",
    "# r2:  0.961\n",
    "# MAE (Mean absolute error): 108.7497\n",
    "# Median absolute error: 35.78\n",
    "# RMSE: 271.2456\n",
    "# explained_variance:  0.961\n",
    "# mape: 15849072058643.87\n",
    "### ~same results using with/without \"Variable\" categorical feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18493d88",
   "metadata": {},
   "source": [
    "* diff target:\n",
    "```\n",
    "CB model + Feats\n",
    "1\n",
    "...\n",
    "5\n",
    "\n",
    "r2: 0.272\n",
    "MAE (Mean absolute error): 87.658\n",
    "Median absolute error: 32.8463\n",
    "RMSE: 200.2333\n",
    "explained_variance:  0.2747\n",
    "mape: 9.3886\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear model + Feats\")\n",
    "df_feat[\"preds\"] = np.NaN\n",
    "evaluate(X=X.select_dtypes(\"number\"),model=LinearRegression())\n",
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81071b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Single feature baseline model\")\n",
    "df_feat[\"preds\"] = np.NaN\n",
    "evaluate(X=X[[\"lag5\"]],model=LinearRegression())\n",
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655672b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.dropna(subset=[\"preds\"])[[\"preds\",\"y_raw\",\"lag5\"]].corr().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17043b5",
   "metadata": {},
   "source": [
    "#### forwarf FS - check why so overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4321e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if DO_RFE_FS:\n",
    "#     from sklearn.feature_selection import SequentialFeatureSelector\n",
    "#     sfs = SequentialFeatureSelector(ElasticNet(warm_start=True,normalize=True,\n",
    "#                                                max_iter=1500), n_features_to_select=15,n_jobs=-1)\n",
    "#     sfs.fit(X.select_dtypes(\"number\"), y)\n",
    "#     print(len(sfs.get_feature_names_out()))\n",
    "#     list(sfs.get_feature_names_out())\n",
    "#     X2 = X.filter([\"variable\"]+list(sfs.get_feature_names_out()),axis=1).copy()\n",
    "#     X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feat[\"preds\"] = np.NaN\n",
    "# evaluate(X=X2.select_dtypes(\"number\"),model=LinearRegression())\n",
    "# y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "# y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "# regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat[\"preds\"] = np.NaN\n",
    "evaluate(X=X2)\n",
    "y_true = df_feat.dropna(subset=[\"preds\"])[\"y_raw\"]\n",
    "y_pred = df_feat.dropna(subset=[\"preds\"])[\"preds\"]\n",
    "\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1033f",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "R2 score for naive lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.reset_index().sort_values([\"variable\",\"year_num\"]).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2: lag5', round(metrics.r2_score(y_true=y_true, y_pred=df_feat.dropna(subset=[\"preds\"])[\"lag5\"]),4))\n",
    "print('r2: lag6', round(metrics.r2_score(y_true=y_true, y_pred=df_feat.dropna(subset=[\"preds\"])[\"lag6\"]),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff83328",
   "metadata": {},
   "source": [
    "### SHAP Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = X.columns[3:6]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_string = 'my name is nik, welc(ome to datagy)'\n",
    "# re.split('\\W+', sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i.replace(\"between 11 years and \",\"\") for i in lst]\n",
    "import re\n",
    "\n",
    "# [truncate(i) for i in lst if i.isnumeric()]\n",
    "# [truncate(i) for i.split() in lst]\n",
    "lst2 = []\n",
    "for i in lst:\n",
    "    i_split = i.replace(\")\",\" )\").split() # makes years uglier\n",
    "#     i_split = re.split('\\W+', i) ## deletes/loses the parantheses, messing up feats\n",
    "    lst2.append(\" \".join([truncate(c) for c in i_split]))\n",
    "lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "import shap\n",
    "\n",
    "# train an XGBoost model\n",
    "# X, y = shap.datasets.boston()\n",
    "# model = xgboost.XGBRegressor().fit(X, y)\n",
    "model = CatBoostRegressor(iterations=500,cat_features= [\"variable\"],\n",
    "                      verbose=False,has_time=True)\n",
    "# model = LinearRegression() ## better results\n",
    "# X = df_feat[[\"variable\"]+num_cols]#.copy() # try values ? \n",
    "# # X = X.fillna(0)\n",
    "# y = df_feat[\"y_raw\"]\n",
    "model.fit(X,y)\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# summarize the effects of all the features\n",
    "shap.plots.beeswarm(shap_values,max_display=15,)\n",
    "# shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f21db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882332f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"year_num\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X[\"year_num\"]>=2018\n",
    "df_future_predictions = X.loc[mask].copy()\n",
    "# model.fit(X,y)\n",
    "df_future_predictions[\"predicted\"] = model.predict(df_future_predictions.drop(columns=[\"predicted\"],errors=\"ignore\"))\n",
    "## check lag of target construction..., \n",
    "df_future_predictions[\"actual_y\"] = y.loc[mask].copy()\n",
    "df_future_predictions = df_future_predictions.filter(['year_num','variable', \"predicted\",\"actual_y\",'lag5'],axis=1)\n",
    "df_future_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc328ae",
   "metadata": {},
   "source": [
    "### Plot Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cdffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat[\"y_raw\"].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ba55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat[\"preds\"].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d50ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feat.loc[df_feat[\"variable\"].str.contains(\"subthalamus\",case=False)]#[[\"y_raw\",\"y_raw_predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_preds(df_feat,\"eeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df[\"variable\"].str.contains(\"neural networks\",case=False)][[\"y_raw\",\"y_raw_predicted\"]].plot(title=\"neural networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_preds(df_feat,\"neural networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b26c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_preds(df_feat,\"artificial neural networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c55075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_preds(df_feat,\"vaccine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_preds(df_feat,\"cannabis\",logScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06711704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"start\"].dt.year>1994][\"variable\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ccbc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ['BRCA2', 'BRCA1', 'carbon nanotubes', 'GWAS']:\n",
    "    plot_var_preds(df_feat,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6f925",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in ['artificial neural networks', 'graph neural network', 'buckyballs',\n",
    "#        'carbon nanotubes', 'BRCA2', 'BRCA1', 'GWAS',\n",
    "       'nanopore', 'metabolome', 'metagenomics', 'miRNA', 'CRISPR',\n",
    "       'biosimilar', 'connectome', 'crispr cas-9',]:\n",
    "    plot_var_preds(df_feat,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e265e32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in ['antibiotic','substance P', 'dopamine', 'fMRI', 'MRI', 'epigenetics',\n",
    "       'carbon dating', 'soy milk', 'mass spectrometry', \n",
    "       'machine learning', 'savant', 'prion']:\n",
    "    plot_var_preds(df_feat,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
